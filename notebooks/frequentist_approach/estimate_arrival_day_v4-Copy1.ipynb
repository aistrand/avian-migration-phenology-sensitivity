{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "from scipy.stats import t\n",
    "import scipy.optimize as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/alvastrand/Documents/OU/Research/notebooks/calculate_arrival_date'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/alvastrand/Documents/OU/Research/data/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/alvastrand/Documents/OU/Research/data'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '0101'\n",
    "end_date = '0731'\n",
    "end_year = 2019\n",
    "month = 'Apr'\n",
    "year_ebird = '2020'\n",
    "countries_states = 'US_states_east_Mississippi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_species_codes) = 19\n"
     ]
    }
   ],
   "source": [
    "subdir = 'output/'\n",
    "filename = 'obligate_aerial_insectivores_ebird_species_codes.csv'\n",
    "\n",
    "df_species_codes = pd.read_csv(subdir + filename)\n",
    "\n",
    "print('len(df_species_codes) =', len(df_species_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>species_code</th>\n",
       "      <th>category</th>\n",
       "      <th>taxon_order</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>report_as</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antrostomus arizonae</td>\n",
       "      <td>Mexican Whip-poor-will</td>\n",
       "      <td>souwpw1</td>\n",
       "      <td>species</td>\n",
       "      <td>3533</td>\n",
       "      <td>Caprimulgiformes</td>\n",
       "      <td>Caprimulgidae</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Antrostomus carolinensis</td>\n",
       "      <td>Chuck-will's-widow</td>\n",
       "      <td>chwwid</td>\n",
       "      <td>species</td>\n",
       "      <td>3510</td>\n",
       "      <td>Caprimulgiformes</td>\n",
       "      <td>Caprimulgidae</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            scientific_name             common_name species_code category  \\\n",
       "0      Antrostomus arizonae  Mexican Whip-poor-will      souwpw1  species   \n",
       "1  Antrostomus carolinensis      Chuck-will's-widow       chwwid  species   \n",
       "\n",
       "   taxon_order             order         family  report_as  \n",
       "0         3533  Caprimulgiformes  Caprimulgidae        NaN  \n",
       "1         3510  Caprimulgiformes  Caprimulgidae        NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_species_codes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 souwpw1 Mexican Whip-poor-will\n",
      "1 chwwid Chuck-will's-widow\n",
      "2 bucnig Buff-collared Nightjar\n",
      "3 whip-p1 Eastern Whip-poor-will\n",
      "4 lesnig Lesser Nighthawk\n",
      "5 comnig Common Nighthawk\n",
      "6 compoo Common Poorwill\n",
      "7 whtswi White-throated Swift\n",
      "8 chiswi Chimney Swift\n",
      "9 vauswi Vaux's Swift\n",
      "10 blkswi Black Swift\n",
      "11 barswa Barn Swallow\n",
      "12 cavswa Cave Swallow\n",
      "13 cliswa Cliff Swallow\n",
      "14 purmar Purple Martin\n",
      "15 banswa Bank Swallow\n",
      "16 nrwswa Northern Rough-winged Swallow\n",
      "17 treswa Tree Swallow\n",
      "18 vigswa Violet-green Swallow\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_species_codes)):\n",
    "      \n",
    "    print(i, df_species_codes['species_code'].iloc[i], df_species_codes['common_name'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_of_season_arrival_day(species, start_date, end_date, start_year, end_year, month, year_ebird, sampled, \n",
    "                                    df, list_grid_cells, list_years, *args):\n",
    "    \n",
    "    list_grid_cells_first_of_season = []\n",
    "    list_years_first_of_season = []\n",
    "    list_t_mad = []\n",
    "    list_mad = []\n",
    "\n",
    "    for i in range(len(list_grid_cells)):\n",
    "\n",
    "#         print('i =', i)\n",
    "\n",
    "        grid_cell = list_grid_cells[i]\n",
    "        year = list_years[i]\n",
    "#         print('(grid_cell, year) =', (grid_cell, year))\n",
    "        \n",
    "        # Get data for a given grid cell and year\n",
    "        df_block_year = df[(df['grid_cell'] == grid_cell) & (df['year'] == year)]\n",
    "        df_block_year = df_block_year.reset_index(drop=True)\n",
    "#         print('len(df_block_year) =', len(df_block_year))\n",
    "        \n",
    "        start_index = df_block_year[df_block_year['prop'].notna()].head(1).index[0]\n",
    "#         print('start_index =', start_index)\n",
    "\n",
    "        df_block_year = df_block_year.iloc[start_index:]\n",
    "#         print('len(df_block_year) =', len(df_block_year))\n",
    "\n",
    "        window_size = 7\n",
    "        # window_size?\n",
    "        end_index = start_index + window_size - 1\n",
    "#         print('end_index =', end_index)\n",
    "\n",
    "        confidence = 0.95\n",
    "        z = 1.96\n",
    "\n",
    "        means = []\n",
    "        sems = []\n",
    "        hs = []\n",
    "        lower_bounds = []\n",
    "        upper_bounds = []\n",
    "        \n",
    "        moving_index = start_index\n",
    "#         print('moving_index =', moving_index)\n",
    "\n",
    "        while moving_index < len(df_block_year) - window_size + 1:\n",
    "            \n",
    "            df_sample = df_block_year.iloc[range(moving_index, end_index + 1)]\n",
    "            df_sample = df_sample.dropna()\n",
    "\n",
    "            if len(df_sample) > 1:\n",
    "\n",
    "                weights = df_sample['nb_checklists']\n",
    "                \n",
    "                dof = 0\n",
    "                # ?\n",
    "\n",
    "                weighted_stats = DescrStatsW(df_sample['prop'], weights=weights, ddof=dof)\n",
    "\n",
    "                mean = weighted_stats.mean\n",
    "                \n",
    "                sem = weighted_stats.std_mean\n",
    "\n",
    "#                 h = sem*t.ppf((1 + confidence)/2, len(df_sample) - 1)\n",
    "                h = z*math.sqrt((mean*(1-mean))/weighted_stats.sum_weights)\n",
    "                lower_bound = mean - h\n",
    "                upper_bound = mean + h\n",
    "\n",
    "                means.append(mean)\n",
    "                sems.append(sem)\n",
    "                hs.append(h)\n",
    "                lower_bounds.append(lower_bound)\n",
    "                upper_bounds.append(upper_bound)\n",
    "\n",
    "            else:\n",
    "\n",
    "                means.append(np.nan)\n",
    "                # ?\n",
    "                sems.append(np.nan)\n",
    "                # ?\n",
    "                hs.append(np.nan)\n",
    "                lower_bounds.append(np.nan)\n",
    "                upper_bounds.append(np.nan)\n",
    "\n",
    "            moving_index += 1\n",
    "            end_index += 1\n",
    "\n",
    "        # Index of the first mean that is greater than zero\n",
    "        first_greater_than_zero_index = next((i for i, mean in enumerate(means) if mean > 0), None)\n",
    "#         print('first_greater_than_zero_index:', first_greater_than_zero_index)\n",
    "    \n",
    "#         If there's at least one mean greater than zero:\n",
    "        if first_greater_than_zero_index != None:\n",
    "        \n",
    "#             means[first_greater_than_zero_index] should be greater than zero \n",
    "#             (the first value that is greater than zero).\n",
    "#             print('means[first_greater_than_zero_index]:', means[first_greater_than_zero_index])\n",
    "\n",
    "            first_greater_than_zero_upper_bound = upper_bounds[first_greater_than_zero_index]\n",
    "#             print('first_greater_than_zero_upper_bound:', first_greater_than_zero_upper_bound)\n",
    "\n",
    "            first_greater_than_upper_bound_index = next((i for i, mean in enumerate(means) if \n",
    "                                                         mean > first_greater_than_zero_upper_bound), None)\n",
    "#             print('first_greater_than_upper_bound_index:', first_greater_than_upper_bound_index)\n",
    "\n",
    "#             If there's at least one proportion that exceeds the upper bound of the confidence interval:\n",
    "            if first_greater_than_upper_bound_index != None:\n",
    "        \n",
    "#                 print('means[first_greater_than_upper_bound_index]:', means[first_greater_than_upper_bound_index])\n",
    "\n",
    "                index = first_greater_than_upper_bound_index + window_size - 1\n",
    "#                 print('index:', index)\n",
    "\n",
    "                t_mad = df_block_year.iloc[index]['julian_day']\n",
    "#                 print('t_mad:', t_mad)\n",
    "\n",
    "                mad = df_block_year.iloc[index]['observation_date']\n",
    "#                 print('mad:', mad)\n",
    "                \n",
    "#                 print(df_block_year.iloc[index])\n",
    "                \n",
    "#                 print(df_block_year.iloc[range(first_greater_than_zero_index, \n",
    "#                                                first_greater_than_zero_index + window_size)])\n",
    "                \n",
    "#                 print(df_block_year.iloc[range(first_greater_than_upper_bound_index, \n",
    "#                                                first_greater_than_upper_bound_index + window_size)])\n",
    "                \n",
    "            # If there aren't any proportions that exceed the upper bound of the confidence interval:\n",
    "            elif first_greater_than_upper_bound_index == None:\n",
    "\n",
    "                t_mad = np.nan\n",
    "                mad = np.nan\n",
    "        \n",
    "#             print(len(df_block_year.iloc[range(start_index, len(df_block_year) - window_size + 1)][\n",
    "#                 'observation_date_dt']))\n",
    "#             print(len(means))\n",
    "#             print(len(upper_bounds))\n",
    "            \n",
    "            assert(len(df_block_year.iloc[range(start_index, len(df_block_year) - window_size + 1)][\n",
    "                'observation_date_dt']) == len(means))\n",
    "        \n",
    "#             # Means and upper bounds\n",
    "#             plt.figure(figsize=(12.0, 4.0))\n",
    "#             plt.scatter(df_block_year.iloc[range(start_index, len(df_block_year) - window_size + 1)][\n",
    "#                 'observation_date_dt'], means)\n",
    "#             plt.scatter(df_block_year.iloc[range(start_index, len(df_block_year) - window_size + 1)][\n",
    "#                 'observation_date_dt'], upper_bounds)\n",
    "#             plt.show()\n",
    "\n",
    "#             # Proportions\n",
    "#             plt.figure(figsize=(12.0, 4.0))\n",
    "#             plt.scatter(df_block_year['observation_date_dt'], df_block_year['prop'])\n",
    "#             plt.show()\n",
    "\n",
    "#             plt.figure(figsize=(12.0, 4.0))\n",
    "#             plt.scatter(df_block_year['observation_date_dt'], df_block_year['prop_arcsine'])\n",
    "#             plt.show()\n",
    "\n",
    "        # If there aren't any means greater than zero:\n",
    "        elif first_greater_than_zero_index == None:\n",
    "\n",
    "            t_mad = np.nan\n",
    "            mad = np.nan\n",
    "\n",
    "        list_grid_cells_first_of_season.append(grid_cell)\n",
    "        list_years_first_of_season.append(year)\n",
    "        list_t_mad.append(t_mad)\n",
    "        list_mad.append(mad)\n",
    "\n",
    "    df_first_of_season = pd.DataFrame({'grid_cell': list_grid_cells_first_of_season, \n",
    "                                       'year': list_years_first_of_season, \n",
    "                                       'first_of_season_arrival_day': list_t_mad, \n",
    "                                       'first_of_season_arrival_date': list_mad})\n",
    "\n",
    "    print('len(df_first_of_season):', len(df_first_of_season))\n",
    "    \n",
    "    # Filter\n",
    "\n",
    "    df_first_of_season = df_first_of_season.dropna()\n",
    "\n",
    "    print('len(df_first_of_season):', len(df_first_of_season))\n",
    "\n",
    "    subdir = 'eBird/ebd_output/'\n",
    "\n",
    "    if args != ():\n",
    "\n",
    "        countries_states = args[0]\n",
    "        \n",
    "        if sampled == 1:\n",
    "            \n",
    "            string = 'sampled'\n",
    "            \n",
    "            random_state = args[1]\n",
    "            \n",
    "            filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "            '_' + actual_start_date + '_' + actual_end_date + \\\n",
    "            '_complete_zerofilled_grid_cells_proportions_first_of_season_' + str(start_year) + '_' + \\\n",
    "            str(end_year) + '_' + string + '_' + str(random_state) + '_rel' + month + '-' + year_ebird + '_v2.csv'\n",
    "            \n",
    "            # Incorrect!\n",
    "            \n",
    "#             filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "#             '_' + actual_start_date + '_' + actual_end_date + \\\n",
    "#             '_complete_zerofilled_grid_cells_proportions_first_of_season_' + str(start_year) + '_' + \\\n",
    "#             str(end_year) + '_' + string + '_' + str(random_state) + '_rel' + month + '-' + year_ebird + '.csv'\n",
    "            \n",
    "#             filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "#             '_complete_zerofilled_grid_cells_proportions_first_of_season_' + str(start_year) + '_' + \\\n",
    "#             str(end_year) + '_' + string + '_' + str(random_state) + '_rel' + month + '-' + year_ebird + '.csv'\n",
    "\n",
    "        elif sampled == 0:\n",
    "            \n",
    "            string = 'not_sampled'\n",
    "            \n",
    "            filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "            '_' + actual_start_date + '_' + actual_end_date + \\\n",
    "            '_complete_zerofilled_grid_cells_proportions_first_of_season_' + str(start_year) + '_' + \\\n",
    "            str(end_year) + '_' + string + '_rel' + month + '-' + year_ebird + '_v2.csv'\n",
    "            \n",
    "            # Incorrect!\n",
    "            \n",
    "#             filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "#             '_' + actual_start_date + '_' + actual_end_date + \\\n",
    "#             '_complete_zerofilled_grid_cells_proportions_first_of_season_' + str(start_year) + '_' + \\\n",
    "#             str(end_year) + '_' + string + '_rel' + month + '-' + year_ebird + '.csv'\n",
    "            \n",
    "#             filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "#             '_complete_zerofilled_grid_cells_proportions_first_of_season_' + str(start_year) + '_' + \\\n",
    "#             str(end_year) + '_' + string + '_rel' + month + '-' + year_ebird + '.csv'\n",
    "            \n",
    "        print('filename =', filename)\n",
    "\n",
    "#     df_first_of_season.to_csv(subdir + filename, index=False)\n",
    "\n",
    "    return df_block_year, df_first_of_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_function(t, a, b, c):\n",
    "    return c/(1 + a * np.exp(-b * t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_mean_arrival_day(species, start_date, end_date, start_year, end_year, month, year_ebird, df, \n",
    "                         list_grid_cells, list_years, *args):\n",
    "\n",
    "    bounds = (0, [1000000, 100, 1])\n",
    "\n",
    "    list_grid_cells_logistic = []\n",
    "    list_years_logistic = []\n",
    "    list_p0 = []\n",
    "    list_popt = []\n",
    "    list_r_squared = []\n",
    "    list_m_a_day = []\n",
    "    list_m_a_date = []\n",
    "    list_lower_bound_c = []\n",
    "    list_upper_bound_c = []\n",
    "    list_lower_bound_day = []\n",
    "    list_upper_bound_day = []\n",
    "    list_ci_nb_days = []\n",
    "    cnt_errors = 0\n",
    "\n",
    "    for i in range(len(list_grid_cells)):\n",
    "        \n",
    "#         print('i =', i)\n",
    "        \n",
    "        grid_cell = list_grid_cells[i]\n",
    "        year = list_years[i]\n",
    "        print('(grid_cell, year) =', (grid_cell, year))\n",
    "\n",
    "        # Get data for a given grid cell and year\n",
    "        df_block_year = df[(df['grid_cell'] == grid_cell) & (df['year'] == year)]\n",
    "        df_block_year = df_block_year.reset_index(drop=True)\n",
    "#         print('len(df_block_year) =', len(df_block_year))\n",
    "        \n",
    "        df_block_year_nas = df_block_year.copy()\n",
    "        df_block_year = df_block_year.dropna()\n",
    "\n",
    "        p0 = []\n",
    "        for j in range(3):\n",
    "            p0.append(random.uniform(0, 1))\n",
    "#         print(p0)\n",
    "\n",
    "        x = df_block_year['julian_day']\n",
    "        y = df_block_year['prop']\n",
    "\n",
    "#         try:\n",
    "        # Nonlinear least squares optimization\n",
    "        popt, pcov = optim.curve_fit(logistic_function, x, y, bounds=bounds, p0=p0)\n",
    "\n",
    "        a_optim, b_optim, c_optim = popt\n",
    "#         print(popt)\n",
    "\n",
    "        residuals = y - logistic_function(x, a_optim, b_optim, c_optim)\n",
    "        ss_res = np.sum(residuals**2)\n",
    "        ss_tot = np.sum((y - np.mean(y))**2)\n",
    "        r_squared = 1 - (ss_res/ss_tot)\n",
    "        print('r_squared =', r_squared)\n",
    "\n",
    "        # Time step for mean arrival date\n",
    "        m_a_day = np.log(a_optim)/b_optim\n",
    "#         print('m_a_day =', m_a_day)\n",
    "\n",
    "        # Mean arrival date\n",
    "        m_a_date_round = df_block_year_nas[\n",
    "            df_block_year_nas['julian_day'] == round(m_a_day)]['observation_date'].values[0]\n",
    "#         df_block_year_nas?\n",
    "        print('m_a_date_round =', m_a_date_round)\n",
    "\n",
    "#         # Mean arrival date, rounded down\n",
    "#         m_a_date_floor = df_block_year_nas[\n",
    "#             df_block_year_nas['t'] == math.floor(m_a_day)]['observation_date'].values[0]\n",
    "#         print(m_a_date_floor)\n",
    "\n",
    "#         # Mean arrival date, rounded up\n",
    "#         m_a_date_ceil = df_block_year_nas[\n",
    "#             df_block_year_nas['t'] == math.ceil(m_a_day)]['observation_date'].values[0]\n",
    "#         print(m_a_date_ceil)\n",
    "\n",
    "        lower_bound_c = (2.5/100)*c_optim\n",
    "#         print('lower_bound_c =', lower_bound_c)\n",
    "\n",
    "        upper_bound_c = (97.5/100)*c_optim\n",
    "#         print('upper_bound_c =', upper_bound_c)\n",
    "\n",
    "        lower_bound_day = -np.log((1/a_optim)*(c_optim/lower_bound_c - 1))/b_optim\n",
    "#         print('lower_bound_day =', lower_bound_day)\n",
    "\n",
    "        upper_bound_day = -np.log((1/a_optim)*(c_optim/upper_bound_c - 1))/b_optim\n",
    "#         print('upper_bound_day =', upper_bound_day)\n",
    "\n",
    "#         print('upper_bound_day - lower_bound_day =', upper_bound_day - lower_bound_day)\n",
    "\n",
    "#         lower_bound_date = df_block_year[df_block_year['prop'] >= lower_bound_c]['observation_date_dt'].min()\n",
    "#         print('lower_bound_date =', lower_bound_date)\n",
    "\n",
    "#         upper_bound_date = df_block_year[df_block_year['prop'] <= upper_bound_c]['observation_date_dt'].max()\n",
    "#         print('upper_bound_date =', upper_bound_date)\n",
    "\n",
    "#         if r_squared >= 0.8:\n",
    "#             print('(grid_cell, year) =', (grid_cell, year))\n",
    "#             print('r_squared =', r_squared)\n",
    "#             print('m_a_date_round =', m_a_date_round)\n",
    "            \n",
    "#             plt.figure(figsize=(12.0, 4.0))\n",
    "#             plt.scatter(df_block_year['observation_date_dt'], y)\n",
    "#             plt.plot(df_block_year['observation_date_dt'], logistic_function(x, a_optim, b_optim, c_optim))\n",
    "#             plt.show()\n",
    "\n",
    "        plt.figure(figsize=(12.0, 4.0))\n",
    "        plt.scatter(df_block_year['observation_date_dt'], y)\n",
    "        plt.plot(df_block_year['observation_date_dt'], logistic_function(x, a_optim, b_optim, c_optim))\n",
    "        plt.show()\n",
    "\n",
    "        list_grid_cells_logistic.append(grid_cell)\n",
    "        list_years_logistic.append(year)\n",
    "        list_p0.append(p0)\n",
    "        list_r_squared.append(r_squared)\n",
    "        list_m_a_day.append(m_a_day)\n",
    "        list_m_a_date.append(m_a_date_round)\n",
    "        list_lower_bound_c.append(lower_bound_c)\n",
    "        list_upper_bound_c.append(upper_bound_c)\n",
    "        list_lower_bound_day.append(lower_bound_day)\n",
    "        list_upper_bound_day.append(upper_bound_day)\n",
    "        list_ci_nb_days.append(upper_bound_day - lower_bound_day)\n",
    "\n",
    "#         except (RuntimeError, IndexError) as e:\n",
    "#             cnt_errors += 1\n",
    "#             assert(\n",
    "#                 (e.args[0] == \n",
    "#                  'Optimal parameters not found: The maximum number of function evaluations is exceeded.') | \n",
    "#                 (e.args[0] == \n",
    "#                  'index 0 is out of bounds for axis 0 with size 0'))\n",
    "\n",
    "#     print(cnt_errors)\n",
    "\n",
    "    df_logistic = pd.DataFrame({'grid_cell': list_grid_cells_logistic, 'year': list_years_logistic, \n",
    "                                'mean_arrival_day': list_m_a_day, 'mean_arrival_date': list_m_a_date, \n",
    "                                'r_squared': list_r_squared, 'ci_nb_days': list_ci_nb_days})\n",
    "\n",
    "    print('len(df_logistic) =', len(df_logistic))\n",
    "    \n",
    "    subdir = 'eBird/ebd_output/'\n",
    "    \n",
    "    if args != ():\n",
    "\n",
    "        countries_states = args[0]\n",
    "        \n",
    "        if sampled == 1:\n",
    "            \n",
    "            string = 'sampled'\n",
    "            \n",
    "            random_state = args[1]\n",
    "        \n",
    "#             filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "#             '_complete_zerofilled_grid_cell_' + str(grid_cell) + '_proportions_mean_' + str(start_year) + '_' + \\\n",
    "#             str(end_year) + '_' + string + '_' + str(random_state) + '_rel' + month + '-' + year_ebird + '.csv'\n",
    "            \n",
    "            filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "            '_complete_zerofilled_grid_cells_proportions_mean_' + str(start_year) + '_' + \\\n",
    "            str(end_year) + '_' + string + '_' + str(random_state) + '_rel' + month + '-' + year_ebird + '.csv'\n",
    "        \n",
    "        elif sampled == 0:\n",
    "            \n",
    "            string = 'not_sampled'\n",
    "            \n",
    "#             filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "#             '_complete_zerofilled_grid_cell_' + str(grid_cell) + '_proportions_mean_' + str(start_year) + '_' + \\\n",
    "#             str(end_year) + '_' + string + '_rel' + month + '-' + year_ebird + '.csv'\n",
    "\n",
    "            filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "            '_complete_zerofilled_grid_cells_proportions_mean_' + str(start_year) + '_' + \\\n",
    "            str(end_year) + '_' + string + '_rel' + month + '-' + year_ebird + '.csv'\n",
    "        \n",
    "#             filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "#             '_complete_zerofilled_grid_cells_proportions_mean_rel' + month + '-' + year_ebird + '_v2.csv'\n",
    "        \n",
    "        print('filename =', filename)\n",
    "\n",
    "#     df_logistic.to_csv(subdir + filename, index=False)\n",
    "    \n",
    "    return df_block_year, df_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arrival_days(species, start_date, end_date, start_year, end_year, month, year_ebird, sampled, *args):\n",
    "    \n",
    "    subdir = 'eBird/ebd_output/'\n",
    "\n",
    "    if args != ():\n",
    "\n",
    "        countries_states = args[0]\n",
    "        \n",
    "#         grid_cell = 120\n",
    "#         grid_cell = 128\n",
    "#         grid_cell = 136\n",
    "        \n",
    "#         grid_cell = 117\n",
    "#         grid_cell = 147\n",
    "#         grid_cell = 151\n",
    "        \n",
    "        if sampled == 1:\n",
    "            \n",
    "            string = 'sampled'\n",
    "            \n",
    "            random_state = args[1]\n",
    "            \n",
    "            \n",
    "            # One grid cell\n",
    "            \n",
    "#             filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "#             '_complete_zerofilled_grid_cell_' + str(grid_cell) + '_proportions_' + str(start_year) + '_' + \\\n",
    "#             str(end_year) + '_' + string + '_' + str(random_state) + '_rel' + month + '-' + year_ebird + '.csv'\n",
    "\n",
    "            \n",
    "            filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "            '_complete_zerofilled_grid_cells_proportions_' + str(start_year) + '_' + str(end_year) + '_' + \\\n",
    "            string + '_' + str(random_state) + '_rel' + month + '-' + year_ebird + '.csv'\n",
    "\n",
    "        elif sampled == 0:\n",
    "            \n",
    "            string = 'not_sampled'\n",
    "            \n",
    "            \n",
    "            # One grid cell\n",
    "            \n",
    "#             filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "#             '_complete_zerofilled_grid_cell_' + str(grid_cell) + '_proportions_' + str(start_year) + '_' + \\\n",
    "#             str(end_year) + '_' + string + '_rel' + month + '-' + year_ebird + '.csv'\n",
    "\n",
    "            \n",
    "            filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "            '_complete_zerofilled_grid_cells_proportions_' + str(start_year) + '_' + str(end_year) + '_' + \\\n",
    "            string + '_rel' + month + '-' + year_ebird + '.csv'\n",
    "            \n",
    "        print('filename =', filename)\n",
    "\n",
    "    df = pd.read_csv(subdir + filename)\n",
    "    print('len(df) =', len(df))\n",
    "        \n",
    "    df['observation_date_dt'] = pd.to_datetime(df['observation_date'])\n",
    "    \n",
    "    df_prop_greater_than = df[df['prop'] > 0]\n",
    "    print('len(df_prop_greater_than):', len(df_prop_greater_than))\n",
    "\n",
    "    # Calculate the number of proportions greater than 0 for each grid cell and year\n",
    "    df_prop_greater_than_cnt = df_prop_greater_than[['grid_cell', 'year', 'prop']].groupby(\n",
    "        ['grid_cell', 'year']).count()\n",
    "    df_prop_greater_than_cnt = df_prop_greater_than_cnt.reset_index()\n",
    "    df_prop_greater_than_cnt = df_prop_greater_than_cnt.rename(columns={'prop': 'nb_prop'})\n",
    "    print('len(df_prop_greater_than_cnt):', len(df_prop_greater_than_cnt))\n",
    "\n",
    "    # Filter\n",
    "    \n",
    "#     df_subset = df_prop_greater_than_cnt[df_prop_greater_than_cnt['nb_prop'] >= 10]\n",
    "\n",
    "    df_grid_cells_years = df[['grid_cell', 'year']].drop_duplicates().sort_values(by=['grid_cell', 'year'])\n",
    "\n",
    "    list_grid_cells = list(df_grid_cells_years['grid_cell']) # df_subset\n",
    "    print('len(list_grid_cells) =', len(list_grid_cells))\n",
    "    print('len(list(set(list_grid_cells))) =', len(list(set(list_grid_cells))))\n",
    "\n",
    "    list_years = list(df_grid_cells_years['year']) # df_subset\n",
    "\n",
    "    df_block_year, df_first_of_season = get_first_of_season_arrival_day(\n",
    "        species, start_date, end_date, start_year, end_year, month, year_ebird, sampled, df, list_grid_cells, \n",
    "        list_years, *args)\n",
    "    \n",
    "#     df_block_year, df_logistic = get_mean_arrival_day(\n",
    "#         species, start_date, end_date, start_year, end_year, month, year_ebird, df, list_grid_cells, list_years, \n",
    "#         *args)\n",
    "    \n",
    "#     return df, df_prop_greater_than_cnt, df_grid_cells_years, df_block_year, df_logistic\n",
    "\n",
    "    return df, df_prop_greater_than_cnt, df_grid_cells_years, df_block_year, df_first_of_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "species = 'treswa'\n",
    "# species = 'barswa'\n",
    "# species = 'chiswi'\n",
    "\n",
    "first_year = 2002\n",
    "\n",
    "# start_year = '2002'\n",
    "# start_year = '2003'\n",
    "\n",
    "# start_year = '2010'\n",
    "# start_year = '2012'\n",
    "# start_year = '2009'\n",
    "    \n",
    "# start_year = '2015'\n",
    "# start_year = '2014'\n",
    "\n",
    "actual_start_date = '0101'\n",
    "actual_end_date = '0630'\n",
    "\n",
    "sampled = 1\n",
    "\n",
    "random_state = 1\n",
    "\n",
    "# df_sampled, df_prop_greater_than_cnt_sampled, df_grid_cells_years_sampled, df_block_year_sampled, \\\n",
    "# df_first_of_season_sampled = get_arrival_days(\n",
    "#     species, start_date, end_date, start_year, end_year, month, year_ebird, sampled, countries_states, \n",
    "#     random_state)\n",
    "\n",
    "# df_sampled, df_prop_greater_than_cnt_sampled, df_grid_cells_years_sampled, df_block_year_sampled, \\\n",
    "# df_logistic_sampled = get_arrival_days(\n",
    "#     species, start_date, end_date, start_year, end_year, month, year_ebird, sampled, countries_states, random_state)\n",
    "\n",
    "# for random_state in range(1, 6):\n",
    "    \n",
    "#     df_sampled, df_prop_greater_than_cnt_sampled, df_grid_cells_years_sampled, df_block_year_sampled, \\\n",
    "#     df_first_of_season_sampled = get_arrival_days(\n",
    "#         species, start_date, end_date, start_year, end_year, month, year_ebird, sampled, countries_states, \n",
    "#         random_state)\n",
    "\n",
    "# for start_year in range(first_year, end_year + 1):\n",
    "    \n",
    "#     start_year = str(start_year)\n",
    "#     print('start_year =', start_year)\n",
    "\n",
    "#     end_year = str(end_year)\n",
    "\n",
    "#     df_sampled, df_prop_greater_than_cnt_sampled, df_grid_cells_years_sampled, df_block_year_sampled, \\\n",
    "#     df_first_of_season_sampled = get_arrival_days(\n",
    "#         species, start_date, end_date, start_year, end_year, month, year_ebird, sampled, countries_states, \n",
    "#         random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_year = 2013\n",
      "filename = ebd_US_states_east_Mississippi_treswa_0101_0731_complete_zerofilled_grid_cells_proportions_2013_2019_not_sampled_relApr-2020.csv\n",
      "len(df) = 92491\n",
      "len(df_prop_greater_than): 49678\n",
      "len(df_prop_greater_than_cnt): 511\n",
      "len(list_grid_cells) = 511\n",
      "len(list(set(list_grid_cells))) = 73\n",
      "len(df_first_of_season): 511\n",
      "len(df_first_of_season): 505\n",
      "filename = ebd_US_states_east_Mississippi_treswa_0101_0731_0101_0630_complete_zerofilled_grid_cells_proportions_first_of_season_2013_2019_not_sampled_relApr-2020_v2.csv\n"
     ]
    }
   ],
   "source": [
    "sampled = 0\n",
    "\n",
    "# df_not_sampled, df_prop_greater_than_cnt_not_sampled, df_grid_cells_years_not_sampled, df_block_year_not_sampled, \\\n",
    "# df_first_of_season_not_sampled = get_arrival_days(\n",
    "#     species, start_date, end_date, start_year, end_year, month, year_ebird, sampled, countries_states)\n",
    "\n",
    "# df_not_sampled, df_prop_greater_than_cnt_not_sampled, df_grid_cells_years_not_sampled, df_block_year_not_sampled, \\\n",
    "# df_logistic_not_sampled = get_arrival_days(\n",
    "#     species, start_date, end_date, start_year, end_year, month, year_ebird, sampled, countries_states)\n",
    "\n",
    "# for start_year in range(first_year, end_year + 1):\n",
    "    \n",
    "start_year = '2013'\n",
    "    \n",
    "start_year = str(start_year)\n",
    "print('start_year =', start_year)\n",
    "\n",
    "end_year = str(end_year)\n",
    "\n",
    "df_not_sampled, df_prop_greater_than_cnt_not_sampled, df_grid_cells_years_not_sampled, \\\n",
    "df_block_year_not_sampled, df_first_of_season_not_sampled = get_arrival_days(\n",
    "    species, start_date, end_date, start_year, end_year, month, year_ebird, sampled, countries_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_cell</th>\n",
       "      <th>year</th>\n",
       "      <th>julian_day</th>\n",
       "      <th>observation_date</th>\n",
       "      <th>nb_checklists</th>\n",
       "      <th>nb_checklists_species</th>\n",
       "      <th>prop</th>\n",
       "      <th>prop_arcsine</th>\n",
       "      <th>observation_date_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>14</td>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>15</td>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>16</td>\n",
       "      <td>2013-01-16</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>17</td>\n",
       "      <td>2013-01-17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>18</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>19</td>\n",
       "      <td>2013-01-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>20</td>\n",
       "      <td>2013-01-20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    grid_cell  year  julian_day observation_date  nb_checklists  \\\n",
       "0           5  2013           1       2013-01-01           10.0   \n",
       "1           5  2013           2       2013-01-02            4.0   \n",
       "2           5  2013           3       2013-01-03            8.0   \n",
       "3           5  2013           4       2013-01-04            4.0   \n",
       "4           5  2013           5       2013-01-05            3.0   \n",
       "5           5  2013           6       2013-01-06            1.0   \n",
       "6           5  2013           7       2013-01-07            2.0   \n",
       "7           5  2013           8       2013-01-08           10.0   \n",
       "8           5  2013           9       2013-01-09            NaN   \n",
       "9           5  2013          10       2013-01-10            1.0   \n",
       "10          5  2013          11       2013-01-11            1.0   \n",
       "11          5  2013          12       2013-01-12            2.0   \n",
       "12          5  2013          13       2013-01-13            8.0   \n",
       "13          5  2013          14       2013-01-14            3.0   \n",
       "14          5  2013          15       2013-01-15            1.0   \n",
       "15          5  2013          16       2013-01-16           13.0   \n",
       "16          5  2013          17       2013-01-17            3.0   \n",
       "17          5  2013          18       2013-01-18            2.0   \n",
       "18          5  2013          19       2013-01-19            NaN   \n",
       "19          5  2013          20       2013-01-20            2.0   \n",
       "\n",
       "    nb_checklists_species  prop  prop_arcsine observation_date_dt  \n",
       "0                     0.0   0.0           0.0          2013-01-01  \n",
       "1                     0.0   0.0           0.0          2013-01-02  \n",
       "2                     0.0   0.0           0.0          2013-01-03  \n",
       "3                     0.0   0.0           0.0          2013-01-04  \n",
       "4                     0.0   0.0           0.0          2013-01-05  \n",
       "5                     0.0   0.0           0.0          2013-01-06  \n",
       "6                     0.0   0.0           0.0          2013-01-07  \n",
       "7                     0.0   0.0           0.0          2013-01-08  \n",
       "8                     NaN   NaN           NaN          2013-01-09  \n",
       "9                     0.0   0.0           0.0          2013-01-10  \n",
       "10                    0.0   0.0           0.0          2013-01-11  \n",
       "11                    0.0   0.0           0.0          2013-01-12  \n",
       "12                    0.0   0.0           0.0          2013-01-13  \n",
       "13                    0.0   0.0           0.0          2013-01-14  \n",
       "14                    0.0   0.0           0.0          2013-01-15  \n",
       "15                    0.0   0.0           0.0          2013-01-16  \n",
       "16                    0.0   0.0           0.0          2013-01-17  \n",
       "17                    0.0   0.0           0.0          2013-01-18  \n",
       "18                    NaN   NaN           NaN          2013-01-19  \n",
       "19                    0.0   0.0           0.0          2013-01-20  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_sampled.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_sampled['grid_cell'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92491"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_not_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92491"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "73*7*181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_not_sampled['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_not_sampled[df_not_sampled['grid_cell'] == 5]['julian_day'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prop_greater_than_cnt_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_prop_greater_than_cnt_sampled['nb_prop'].value_counts().to_frame().reset_index().sort_values(by='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prop_greater_than_cnt_not_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_cells_years_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_cells_years_not_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_block_year_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_block_year_not_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_first_of_season_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_first_of_season_not_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_logistic_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_logistic_not_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df['nb_checklists'].value_counts(sort=False).to_frame().reset_index().sort_values(by=['index']).rename(\n",
    "#     columns={'index': 'nb_checklists', 'nb_checklists': 'cnt_grid_cells_observation_dates'}).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cnt_years = df['year'].value_counts(sort=False).to_frame().reset_index()\n",
    "# df_cnt_years = df_cnt_years.rename(columns={'index': 'year', 'year': 'cnt_grid_cells_dates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cnt_years.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdir = 'eBird/ebd_output/'\n",
    "\n",
    "# filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "# '_complete_zerofilled_grid_cells_proportions_cnt_years_rel' + month + '-' + year_ebird + '.csv'\n",
    "# print(filename)\n",
    "        \n",
    "# df_cnt_years.to_csv(subdir + filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# species_cnt = 0\n",
    "\n",
    "# for i in range(len(df_species_codes)):\n",
    "    \n",
    "#     print(i)\n",
    "  \n",
    "#     species = df_species_codes['species_code'].iloc[i]\n",
    "#     print(species)\n",
    "    \n",
    "#     if ((species == 'souwpw1') | (species == 'bucnig') | (species == 'compoo') | (species == 'whtswi') | \n",
    "#         (species == \"blkswi\") | (species == \"treswa\")): #\n",
    "#         continue\n",
    "    \n",
    "#     df, df_cnt_checklists, df_cnt_checklists_species, df_prop_greater_than, df_prop_greater_than_cnt, \\\n",
    "# df_subset = get_arrival_days(species, start_date, end_date, month, year_ebird, countries_states)\n",
    "    \n",
    "#     species_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(species_cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
