{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "Calculate the proportion of checklists with at least one observation of a given species for each grid cell and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/alvastrand/Documents/OU/Research/notebooks/calculate_arrival_date'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/alvastrand/Documents/OU/Research/data/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/alvastrand/Documents/OU/Research/data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '0101'\n",
    "end_date = '0731'\n",
    "month = 'Apr'\n",
    "year = '2020'\n",
    "countries_states = 'US_states_east_Mississippi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df) = 19\n"
     ]
    }
   ],
   "source": [
    "subdir = 'output/'\n",
    "filename = \"obligate_aerial_insectivores_ebird_species_codes.csv\"\n",
    "\n",
    "df = pd.read_csv(subdir + filename)\n",
    "\n",
    "print('len(df) =', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>species_code</th>\n",
       "      <th>category</th>\n",
       "      <th>taxon_order</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>report_as</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antrostomus arizonae</td>\n",
       "      <td>Mexican Whip-poor-will</td>\n",
       "      <td>souwpw1</td>\n",
       "      <td>species</td>\n",
       "      <td>3533</td>\n",
       "      <td>Caprimulgiformes</td>\n",
       "      <td>Caprimulgidae</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Antrostomus carolinensis</td>\n",
       "      <td>Chuck-will's-widow</td>\n",
       "      <td>chwwid</td>\n",
       "      <td>species</td>\n",
       "      <td>3510</td>\n",
       "      <td>Caprimulgiformes</td>\n",
       "      <td>Caprimulgidae</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            scientific_name             common_name species_code category  \\\n",
       "0      Antrostomus arizonae  Mexican Whip-poor-will      souwpw1  species   \n",
       "1  Antrostomus carolinensis      Chuck-will's-widow       chwwid  species   \n",
       "\n",
       "   taxon_order             order         family  report_as  \n",
       "0         3533  Caprimulgiformes  Caprimulgidae        NaN  \n",
       "1         3510  Caprimulgiformes  Caprimulgidae        NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 souwpw1 Mexican Whip-poor-will\n",
      "1 chwwid Chuck-will's-widow\n",
      "2 bucnig Buff-collared Nightjar\n",
      "3 whip-p1 Eastern Whip-poor-will\n",
      "4 lesnig Lesser Nighthawk\n",
      "5 comnig Common Nighthawk\n",
      "6 compoo Common Poorwill\n",
      "7 whtswi White-throated Swift\n",
      "8 chiswi Chimney Swift\n",
      "9 vauswi Vaux's Swift\n",
      "10 blkswi Black Swift\n",
      "11 barswa Barn Swallow\n",
      "12 cavswa Cave Swallow\n",
      "13 cliswa Cliff Swallow\n",
      "14 purmar Purple Martin\n",
      "15 banswa Bank Swallow\n",
      "16 nrwswa Northern Rough-winged Swallow\n",
      "17 treswa Tree Swallow\n",
      "18 vigswa Violet-green Swallow\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "      \n",
    "    print(i, df['species_code'].iloc[i], df['common_name'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_of_function(species, start_date, end_date, month, year, random_state, *args):\n",
    "    \n",
    "    subdir = 'eBird/ebd_output/'\n",
    "    \n",
    "    if args != ():\n",
    "        \n",
    "        countries_states = args[0]\n",
    "        \n",
    "        filename = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "        '_complete_zerofilled_grid_cells_rel' + month + '-' + year + '.csv'\n",
    "        print('filename =', filename)\n",
    "    \n",
    "    df = pd.read_csv(subdir + filename)\n",
    "    print('df.shape =', df.shape)\n",
    "    \n",
    "    df = df[['checklist_id', 'observation_date', 'species_observed', 'grid_cell']]\n",
    "    \n",
    "    df['species_observed_binary_values'] = np.where(df['species_observed'] == True, 1.0, 0.0)\n",
    "    df['year'] = df['observation_date'].astype(str).str[:4]\n",
    "    df['year'] = pd.to_numeric(df['year'])\n",
    "    \n",
    "    df = df[['grid_cell', 'year', 'checklist_id', 'observation_date', 'species_observed_binary_values']]\n",
    "    \n",
    "    # Filter\n",
    "\n",
    "    df = df[df['year'] != 2020]\n",
    "    print('len(df) =', len(df))\n",
    "    \n",
    "#     first_year = 2002\n",
    "    first_year = 2003\n",
    "#     first_year = 2004\n",
    "\n",
    "#     first_year = 2010\n",
    "#     first_year = 2012\n",
    "#     first_year = 2009\n",
    "    \n",
    "#     first_year = 2015\n",
    "#     first_year = 2014\n",
    "\n",
    "    for start_year in range(first_year, first_year + 1):\n",
    "        \n",
    "        print('start_year =', start_year)\n",
    "        \n",
    "        # Filter\n",
    "\n",
    "        df = df[df['year'] >= start_year]\n",
    "        print('len(df) =', len(df))\n",
    "        \n",
    "#         grid_cell = 120\n",
    "#         grid_cell = 128\n",
    "#         grid_cell = 136\n",
    "            \n",
    "#         grid_cell = 117\n",
    "#         grid_cell = 147\n",
    "#         grid_cell = 151\n",
    "\n",
    "        # Filter\n",
    "        \n",
    "#         df = df[df['grid_cell'] == grid_cell]\n",
    "#         print('len(df) =', len(df))\n",
    "\n",
    "        df_cnt = df[['checklist_id', 'grid_cell', 'observation_date']].groupby(\n",
    "            ['grid_cell', 'observation_date']).count()\n",
    "        df_cnt = df_cnt.rename(columns={'checklist_id': 'nb_checklists'})\n",
    "        df_cnt = df_cnt.reset_index()\n",
    "        print('len(df_cnt) =', len(df_cnt))\n",
    "        print(\"len(df_cnt['grid_cell'].unique()) =\", len(df_cnt['grid_cell'].unique()))\n",
    "\n",
    "        start_month = 1\n",
    "        start_day = 1\n",
    "\n",
    "        end_month = 6\n",
    "        # ?\n",
    "        end_day = 30\n",
    "        # ?\n",
    "        \n",
    "        end_year = 2019\n",
    "\n",
    "        start_date_dt = date(end_year, start_month, start_day)\n",
    "#         print('start_date_dt =', start_date_dt)\n",
    "\n",
    "        end_date_dt = date(end_year, end_month, end_day)\n",
    "#         print('end_date_dt =', end_date_dt)\n",
    "        \n",
    "        cnt_days = (end_date_dt - start_date_dt).days + 1\n",
    "        print('cnt_days =', cnt_days)\n",
    "        \n",
    "        julian_days = list(range(1, cnt_days + 1)) * len(range(start_year, end_year + 1))\n",
    "        assert(len(julian_days) == cnt_days * len(range(start_year, end_year + 1)))\n",
    "#         print('julian_days[:2] =', julian_days[:2])\n",
    "        \n",
    "        dates = [pd.date_range(str(i) + '-01-01', periods=cnt_days) for i in range(start_year, end_year + 1)]\n",
    "        assert(len(dates) == len(range(start_year, end_year + 1)))\n",
    "#         print('dates[0][:2] =', dates[0][:2])\n",
    "        \n",
    "        dates = [list(date.strftime('%Y-%m-%d')) for date in dates]\n",
    "        assert(len(dates) == len(range(start_year, end_year + 1)))\n",
    "#         print('dates[0][:2] =', dates[0][:2])\n",
    "#         print([date[-1] for date in dates])\n",
    "        \n",
    "        dates = [i for sublist in dates for i in sublist]\n",
    "        assert(len(dates) == cnt_days * len(range(start_year, end_year + 1)))\n",
    "#         print('dates[:2] =', dates[:2])\n",
    "        \n",
    "        df_julian_days_dates = pd.DataFrame({'julian_day': julian_days, 'observation_date': dates})\n",
    "        df_julian_days_dates = df_julian_days_dates.sort_values(by=['julian_day', 'observation_date'])\n",
    "        df_julian_days_dates = df_julian_days_dates.reset_index(drop=True)\n",
    "        assert(len(df_julian_days_dates) == cnt_days * len(range(start_year, end_year + 1)))\n",
    "        \n",
    "        df_cnt = df_cnt.merge(df_julian_days_dates, on='observation_date')\n",
    "        df_cnt = df_cnt[['grid_cell', 'julian_day', 'observation_date', 'nb_checklists']]\n",
    "        df_cnt = df_cnt.sort_values(by=['grid_cell', 'julian_day', 'observation_date'])\n",
    "        df_cnt = df_cnt.reset_index(drop=True)\n",
    "        \n",
    "        list_grid_cells_repeated = list(df_cnt['grid_cell'].unique()) * len(df_julian_days_dates)\n",
    "        list_grid_cells_repeated = sorted(list_grid_cells_repeated)\n",
    "        assert(len(list_grid_cells_repeated) == len(df_cnt['grid_cell'].unique()) * len(df_julian_days_dates))\n",
    "#         print('list_grid_cells_repeated[:2] =', list_grid_cells_repeated[:2])\n",
    "        \n",
    "        list_julian_days_repeated = list(df_julian_days_dates['julian_day']) * len(df_cnt['grid_cell'].unique())\n",
    "        assert(len(list_julian_days_repeated) == len(df_cnt['grid_cell'].unique()) * len(df_julian_days_dates))\n",
    "#         print('list_julian_days_repeated[:2] =', list_julian_days_repeated[:2])\n",
    "        \n",
    "        list_dates_repeated = list(df_julian_days_dates['observation_date']) * len(df_cnt['grid_cell'].unique())\n",
    "        assert(len(list_dates_repeated) == len(df_cnt['grid_cell'].unique()) * len(df_julian_days_dates))\n",
    "#         print('list_dates_repeated[:2] =', list_dates_repeated[:2])\n",
    "        \n",
    "        df_grid_cells_days_dates = pd.DataFrame({'grid_cell': list_grid_cells_repeated, \n",
    "                                                 'julian_day': list_julian_days_repeated, \n",
    "                                                 'observation_date': list_dates_repeated})\n",
    "        assert(len(df_grid_cells_days_dates) == len(df_cnt['grid_cell'].unique()) * len(df_julian_days_dates))\n",
    "        \n",
    "        df_cnt_grid_cells_days_dates = df_grid_cells_days_dates.merge(\n",
    "            df_cnt, how='left', on=['grid_cell', 'julian_day', 'observation_date'])\n",
    "        df_cnt_grid_cells_days_dates['nb_checklists'] = df_cnt_grid_cells_days_dates['nb_checklists'].fillna(0)\n",
    "        df_cnt_grid_cells_days_dates['nb_checklists'] = df_cnt_grid_cells_days_dates['nb_checklists'].astype(int)\n",
    "        assert(len(df_cnt_grid_cells_days_dates) == len(df_grid_cells_days_dates))\n",
    "        \n",
    "        df_min_cnt = df_cnt_grid_cells_days_dates[['grid_cell', 'julian_day', 'nb_checklists']].groupby(\n",
    "            ['grid_cell', 'julian_day']).min()\n",
    "        df_min_cnt = df_min_cnt.rename(columns={'nb_checklists': 'min_nb_checklists'})\n",
    "        df_min_cnt = df_min_cnt.reset_index()\n",
    "        assert(len(df_min_cnt) == len(df_cnt['grid_cell'].unique()) * cnt_days)\n",
    "        \n",
    "        df_cnt_zero = df_min_cnt[['grid_cell', 'min_nb_checklists']].groupby(\n",
    "            ['grid_cell']).agg(lambda x: x.eq(0).sum())\n",
    "        df_cnt_zero = df_cnt_zero.rename(columns={'min_nb_checklists': 'cnt_zero'})\n",
    "        df_cnt_zero = df_cnt_zero.reset_index()\n",
    "        assert(len(df_cnt_zero) == len(df_cnt['grid_cell'].unique()))\n",
    "        \n",
    "        threshold = cnt_days/2\n",
    "        \n",
    "        # Filter\n",
    "        \n",
    "        list_grid_cells = list(df_cnt_zero[df_cnt_zero['cnt_zero'] < threshold]['grid_cell'])\n",
    "        print('len(list_grid_cells):', len(list_grid_cells))\n",
    "        \n",
    "        print(\"len(df_cnt_zero[df_cnt_zero['cnt_zero'] < cnt_days - 1]) =\", \n",
    "              len(df_cnt_zero[df_cnt_zero['cnt_zero'] < cnt_days - 1]))\n",
    "        \n",
    "        \n",
    "        df_grid_cells_threshold = df[df['grid_cell'].isin(list_grid_cells)]\n",
    "        print('len(df_grid_cells_threshold):', len(df_grid_cells_threshold))\n",
    "\n",
    "        # Calculate the number of checklists for each grid cell and date\n",
    "        df_cnt_not_sampled = df_grid_cells_threshold[['checklist_id', 'grid_cell', 'observation_date']].groupby(\n",
    "            ['grid_cell', 'observation_date']).count()\n",
    "        df_cnt_not_sampled = df_cnt_not_sampled.rename(columns={'checklist_id': 'nb_checklists'})\n",
    "        print(len(df_cnt_not_sampled))\n",
    "\n",
    "        # Calculate the number of checklists with at least one observation of the species of interest for each grid \n",
    "        # cell and date\n",
    "        df_sum_not_sampled = df_grid_cells_threshold[\n",
    "            ['species_observed_binary_values', 'grid_cell', 'observation_date']].groupby(\n",
    "            ['grid_cell', 'observation_date']).sum()\n",
    "        df_sum_not_sampled = df_sum_not_sampled.rename(\n",
    "            columns={'species_observed_binary_values': 'nb_checklists_species'})\n",
    "        assert(len(df_sum_not_sampled) == len(df_cnt_not_sampled))\n",
    "\n",
    "        df_grp_not_sampled = df_cnt_not_sampled.merge(df_sum_not_sampled, left_index=True, right_index=True)\n",
    "        # Calculate the proportion of checklists with at least one observation of the species of interest for each \n",
    "        # grid cell and date\n",
    "        df_grp_not_sampled['prop'] = df_grp_not_sampled['nb_checklists_species']/df_grp_not_sampled['nb_checklists']\n",
    "        df_grp_not_sampled = df_grp_not_sampled.reset_index()\n",
    "        df_grp_not_sampled['year'] = df_grp_not_sampled['observation_date'].astype(str).str[:4]\n",
    "        assert(len(df_grp_not_sampled) == len(df_cnt_not_sampled))\n",
    "        \n",
    "        df_grid_cells_days_dates_years = df_grid_cells_days_dates[\n",
    "            df_grid_cells_days_dates['grid_cell'].isin(list_grid_cells)]\n",
    "        df_grid_cells_days_dates_years = df_grid_cells_days_dates_years.reset_index(drop=True)\n",
    "        df_grid_cells_days_dates_years['year'] = df_grid_cells_days_dates_years[\n",
    "            'observation_date'].astype(str).str[:4]\n",
    "        df_grid_cells_days_dates_years = df_grid_cells_days_dates_years[\n",
    "            ['grid_cell', 'year', 'julian_day', 'observation_date']]\n",
    "        assert(len(df_grid_cells_days_dates_years) == \n",
    "               len(list_grid_cells) * len(range(start_year, end_year + 1)) * cnt_days)\n",
    "        \n",
    "        df_grp_not_sampled_dates = df_grid_cells_days_dates_years.merge(\n",
    "            df_grp_not_sampled, how='left', on=['grid_cell', 'observation_date', 'year'])\n",
    "        df_grp_not_sampled_dates = df_grp_not_sampled_dates[\n",
    "            ['grid_cell', 'year', 'julian_day', 'observation_date', 'nb_checklists', 'nb_checklists_species', \n",
    "             'prop']]\n",
    "        df_grp_not_sampled_dates = df_grp_not_sampled_dates.sort_values(by=['grid_cell', 'year', 'julian_day'])\n",
    "        df_grp_not_sampled_dates = df_grp_not_sampled_dates.reset_index(drop=True)\n",
    "        \n",
    "        # Perform arcsine transformation on the proportions\n",
    "        df_grp_not_sampled_dates['prop_arcsine'] = df_grp_not_sampled_dates['prop'].apply(\n",
    "            lambda x: np.arcsin(math.sqrt(x)))\n",
    "        # ?\n",
    "        \n",
    "        assert(len(df_grp_not_sampled_dates) == len(df_grid_cells_days_dates_years))\n",
    "        \n",
    "        df_sum_prop_not_sampled = df_grp_not_sampled_dates[['grid_cell', 'year', 'prop']].groupby(\n",
    "            ['grid_cell', 'year']).sum()\n",
    "        df_sum_prop_not_sampled = df_sum_prop_not_sampled.reset_index()\n",
    "        df_sum_prop_not_sampled = df_sum_prop_not_sampled.rename(columns={'prop': 'sum_prop'})\n",
    "        assert(len(df_sum_prop_not_sampled) == len(list_grid_cells) * len(range(start_year, end_year + 1)))\n",
    "        \n",
    "        skip_species = 0\n",
    "        \n",
    "        if len(df_sum_prop_not_sampled[df_sum_prop_not_sampled['sum_prop'] == 0]) == len(df_sum_prop_not_sampled):\n",
    "            \n",
    "            skip_species = 1\n",
    "            print('Skip species with species code ' + species + '.')\n",
    "            \n",
    "            break\n",
    "        \n",
    "        if len(df_sum_prop_not_sampled[df_sum_prop_not_sampled['sum_prop'] == 0]) > 0:\n",
    "        \n",
    "            df_sum_prop_zero_not_sampled = df_sum_prop_not_sampled[\n",
    "                df_sum_prop_not_sampled['sum_prop'] == 0][['grid_cell', 'year']]\n",
    "            print('len(df_sum_prop_zero_not_sampled) =', len(df_sum_prop_zero_not_sampled))\n",
    "            print('len(df_sum_prop_not_sampled) - len(df_sum_prop_zero_not_sampled) =', \n",
    "                  len(df_sum_prop_not_sampled) - len(df_sum_prop_zero_not_sampled))\n",
    "            \n",
    "#             print(df_sum_prop_zero_not_sampled.head(2))\n",
    "            \n",
    "            df_grp_not_sampled_dates = df_grp_not_sampled_dates.merge(\n",
    "                df_sum_prop_zero_not_sampled, how='left', on=['grid_cell', 'year'], indicator=True)\n",
    "            assert(len(df_grp_not_sampled_dates) == len(df_grid_cells_days_dates_years))\n",
    "            \n",
    "            df_grp_not_sampled_dates = df_grp_not_sampled_dates[df_grp_not_sampled_dates['_merge'] == 'left_only']\n",
    "            print('len(df_grp_not_sampled_dates) =', len(df_grp_not_sampled_dates))\n",
    "            \n",
    "            df_grp_not_sampled_dates = df_grp_not_sampled_dates.drop(columns=['_merge'])\n",
    "                        \n",
    "        df_sampled = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(list_grid_cells)):\n",
    "\n",
    "#             i = 0\n",
    "\n",
    "            print('i =', i)\n",
    "\n",
    "            grid_cell_threshold = list_grid_cells[i]\n",
    "\n",
    "            df_grid_cell = df[df['grid_cell'] == grid_cell_threshold]\n",
    "            print('len(df_grid_cell) =', len(df_grid_cell))\n",
    "\n",
    "            df_min_cnt_grid_cell = df_min_cnt[df_min_cnt['grid_cell'] == grid_cell_threshold]\n",
    "            df_min_cnt_grid_cell = df_min_cnt_grid_cell.reset_index(drop=True)\n",
    "            assert(len(df_min_cnt_grid_cell) == cnt_days)\n",
    "\n",
    "            df_min_cnt_greater_than_grid_cell = df_min_cnt_grid_cell[df_min_cnt_grid_cell['min_nb_checklists'] > 0]\n",
    "            df_min_cnt_greater_than_grid_cell = df_min_cnt_greater_than_grid_cell.reset_index(drop=True)\n",
    "            print('len(df_min_cnt_greater_than_grid_cell) =', len(df_min_cnt_greater_than_grid_cell))\n",
    "\n",
    "            # observation_date\n",
    "            df_min_cnt_greater_than_dates_grid_cell = df_julian_days_dates.merge(\n",
    "                df_min_cnt_greater_than_grid_cell, on='julian_day')\n",
    "            assert(len(df_min_cnt_greater_than_dates_grid_cell) == \n",
    "                   len(df_min_cnt_greater_than_grid_cell) * len(range(start_year, end_year + 1)))\n",
    "\n",
    "            list_dates_grid_cell = list(df_min_cnt_greater_than_dates_grid_cell['observation_date'])\n",
    "            assert(len(list_dates_grid_cell) == len(df_min_cnt_greater_than_dates_grid_cell))\n",
    "\n",
    "            list_min_cnt_grid_cell = list(df_min_cnt_greater_than_dates_grid_cell['min_nb_checklists'])\n",
    "            assert(len(list_min_cnt_grid_cell) == len(df_min_cnt_greater_than_dates_grid_cell))\n",
    "            \n",
    "            for j in range(len(list_dates_grid_cell)):\n",
    "                \n",
    "#                 j = 0\n",
    "\n",
    "                df_grid_cell_date = df_grid_cell[df_grid_cell['observation_date'] == list_dates_grid_cell[j]]\n",
    "\n",
    "                df_grid_cell_date = df_grid_cell_date.sample(list_min_cnt_grid_cell[j], random_state=random_state)\n",
    "#                 assert(len(df_grid_cell_date) == list_min_cnt_grid_cell[j])\n",
    "\n",
    "                df_sampled = df_sampled.append(df_grid_cell_date)\n",
    "#                 assert(len(df_sampled) == len(df_grid_cell_date))\n",
    "            \n",
    "        print('len(df_sampled):', len(df_sampled))\n",
    "                \n",
    "        # Calculate the number of checklists for each grid cell and date\n",
    "        df_cnt_sampled = df_sampled[['checklist_id', 'grid_cell', 'observation_date']].groupby(\n",
    "            ['grid_cell', 'observation_date']).count()\n",
    "        df_cnt_sampled = df_cnt_sampled.rename(columns={'checklist_id': 'nb_checklists'})\n",
    "        print(len(df_cnt_sampled))\n",
    "\n",
    "        # Calculate the number of checklists with at least one observation of the species of interest for each grid \n",
    "        # cell and date\n",
    "        df_sum_sampled = df_sampled[['species_observed_binary_values', 'grid_cell', 'observation_date']].groupby([\n",
    "            'grid_cell', 'observation_date']).sum()\n",
    "        df_sum_sampled = df_sum_sampled.rename(columns={'species_observed_binary_values': 'nb_checklists_species'})\n",
    "        assert(len(df_sum_sampled) == len(df_cnt_sampled))\n",
    "\n",
    "        df_grp_sampled = df_cnt_sampled.merge(df_sum_sampled, left_index=True, right_index=True)\n",
    "        # Calculate the proportion of checklists with at least one observation of the species of interest for each \n",
    "        # grid cell and date\n",
    "        df_grp_sampled['prop'] = df_grp_sampled['nb_checklists_species']/df_grp_sampled['nb_checklists']\n",
    "        df_grp_sampled = df_grp_sampled.reset_index()\n",
    "        df_grp_sampled['year'] = df_grp_sampled['observation_date'].astype(str).str[:4]\n",
    "        assert(len(df_grp_sampled) == len(df_cnt_sampled))\n",
    "        \n",
    "        df_grp_sampled_dates = df_grid_cells_days_dates_years.merge(\n",
    "            df_grp_sampled, how='left', on=['grid_cell', 'observation_date', 'year'])\n",
    "        df_grp_sampled_dates = df_grp_sampled_dates[\n",
    "            ['grid_cell', 'year', 'julian_day', 'observation_date', 'nb_checklists', 'nb_checklists_species', \n",
    "             'prop']]\n",
    "        df_grp_sampled_dates = df_grp_sampled_dates.sort_values(by=['grid_cell', 'year', 'julian_day'])\n",
    "        df_grp_sampled_dates = df_grp_sampled_dates.reset_index(drop=True)\n",
    "        \n",
    "        # Perform arcsine transformation on the proportions\n",
    "        df_grp_sampled_dates['prop_arcsine'] = df_grp_sampled_dates['prop'].apply(lambda x: np.arcsin(math.sqrt(x)))\n",
    "        # ?\n",
    "        \n",
    "        assert(len(df_grp_sampled_dates) == len(df_grid_cells_days_dates_years))\n",
    "        \n",
    "        df_sum_prop_sampled = df_grp_sampled_dates[['grid_cell', 'year', 'prop']].groupby(\n",
    "            ['grid_cell', 'year']).sum()\n",
    "        df_sum_prop_sampled = df_sum_prop_sampled.reset_index()\n",
    "        df_sum_prop_sampled = df_sum_prop_sampled.rename(columns={'prop': 'sum_prop'})\n",
    "        assert(len(df_sum_prop_sampled) == len(list_grid_cells) * len(range(start_year, end_year + 1)))\n",
    "        \n",
    "        # If there are grid cells and years that only have proportions that are equal to zero\n",
    "        if len(df_sum_prop_sampled[df_sum_prop_sampled['sum_prop'] == 0]) > 0:\n",
    "        \n",
    "            df_sum_prop_zero_sampled = df_sum_prop_sampled[\n",
    "                df_sum_prop_sampled['sum_prop'] == 0][['grid_cell', 'year']]\n",
    "            print('len(df_sum_prop_zero_sampled) =', len(df_sum_prop_zero_sampled))\n",
    "            print('len(df_sum_prop_sampled) - len(df_sum_prop_zero_sampled) =', \n",
    "                  len(df_sum_prop_sampled) - len(df_sum_prop_zero_sampled))\n",
    "            \n",
    "#             print(df_sum_prop_zero_sampled.head(2))\n",
    "            \n",
    "            df_grp_sampled_dates = df_grp_sampled_dates.merge(\n",
    "                df_sum_prop_zero_sampled, how='left', on=['grid_cell', 'year'], indicator=True)\n",
    "            assert(len(df_grp_sampled_dates) == len(df_grid_cells_days_dates_years))\n",
    "            \n",
    "            df_grp_sampled_dates = df_grp_sampled_dates[df_grp_sampled_dates['_merge'] == 'left_only']\n",
    "            print('len(df_grp_sampled_dates) =', len(df_grp_sampled_dates))\n",
    "            \n",
    "            df_grp_sampled_dates = df_grp_sampled_dates.drop(columns=['_merge'])\n",
    "        \n",
    "        # If there's at least one grid cell and year that has at least one proportion that's not equal to zero\n",
    "        if (len(df_sum_prop_sampled[df_sum_prop_sampled['sum_prop'] == 0]) < len(df_sum_prop_sampled)):\n",
    "    \n",
    "            if args != ():\n",
    "\n",
    "                countries_states = args[0]\n",
    "\n",
    "                filename_sampled = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + \\\n",
    "                end_date + '_complete_zerofilled_grid_cells_proportions_' + str(start_year) + '_' + \\\n",
    "                str(end_year) + '_sampled_' + str(random_state) + '_rel' + month + '-' + year + '.csv'\n",
    "\n",
    "#                 filename_sampled = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + \\\n",
    "#                 end_date + '_complete_zerofilled_grid_cell_' + str(grid_cell) + '_proportions_' + \\\n",
    "#                 str(start_year) + '_' + str(end_year) + '_sampled_' + str(random_state) + '_rel' + month + '-' + \\\n",
    "#                 year + '.csv'\n",
    "\n",
    "                filename_not_sampled = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + \\\n",
    "                end_date + '_complete_zerofilled_grid_cells_proportions_' + str(start_year) + '_' + \\\n",
    "                str(end_year) + '_not_sampled_rel' + month + '-' + year + '.csv'\n",
    "\n",
    "#                 filename_not_sampled = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + \\\n",
    "#                 end_date + '_complete_zerofilled_grid_cell_' + str(grid_cell) + '_proportions_' + \\\n",
    "#                 str(start_year) + '_' + str(end_year) + '_not_sampled_rel' + month + '-' + year + '.csv'\n",
    "\n",
    "                print(filename_sampled)\n",
    "                print(filename_not_sampled)\n",
    "\n",
    "            df_grp_sampled_dates.to_csv(subdir + filename_sampled, index=False)\n",
    "            df_grp_not_sampled_dates.to_csv(subdir + filename_not_sampled, index=False)\n",
    "\n",
    "    return df, df_julian_days_dates, df_cnt, df_grid_cells_days_dates, df_cnt_grid_cells_days_dates, df_min_cnt, \\\n",
    "df_cnt_zero, df_grid_cell, df_min_cnt_grid_cell, df_min_cnt_greater_than_grid_cell, \\\n",
    "df_min_cnt_greater_than_dates_grid_cell, df_grid_cell_date, df_sampled, df_cnt_sampled, df_sum_sampled, \\\n",
    "df_grp_sampled, df_grid_cells_threshold, df_cnt_not_sampled, df_sum_not_sampled, df_grp_not_sampled, \\\n",
    "df_grid_cells_days_dates_years, df_grp_sampled_dates, df_grp_not_sampled_dates, df_sum_prop_sampled, \\\n",
    "df_sum_prop_not_sampled, skip_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# species_cnt = 0\n",
    "\n",
    "# for i in range(len(df)):\n",
    "    \n",
    "#     print(i)\n",
    "  \n",
    "#     species = df['species_code'].iloc[i]\n",
    "#     print(species)\n",
    "    \n",
    "#     if ((species == 'souwpw1') | (species == 'bucnig') | (species == 'compoo') | (species == 'whtswi') | \n",
    "#         (species == 'blkswi') | (species == 'treswa') | (species == 'barswa') | (species == 'chwwid') | \n",
    "#         (species == 'whip-p1') | (species == 'lesnig') | (species == 'comnig') | (species == 'chiswi') | \n",
    "#         (species == 'vauswi')):\n",
    "#         continue\n",
    "    \n",
    "#     for random_state in range(1, 6):\n",
    "\n",
    "#         df_grid_cells, df_julian_days_dates, df_cnt, df_grid_cells_days_dates, df_cnt_grid_cells_days_dates, \\\n",
    "#         df_min_cnt, df_cnt_zero, df_grid_cell, df_min_cnt_grid_cell, df_min_cnt_greater_than_grid_cell, \\\n",
    "#         df_min_cnt_greater_than_dates_grid_cell, df_grid_cell_date, df_sampled, df_cnt_sampled, df_sum_sampled, \\\n",
    "#         df_grp_sampled, df_grid_cells_threshold, df_cnt_not_sampled, df_sum_not_sampled, \\\n",
    "#         df_grp_not_sampled, df_grid_cells_days_dates_years, df_grp_sampled_dates, df_grp_not_sampled_dates, \\\n",
    "#         df_sum_prop_sampled, df_sum_prop_not_sampled, skip_species = name_of_function(\n",
    "#             species, start_date, end_date, month, year, random_state, countries_states)\n",
    "        \n",
    "#         if skip_species == 1:\n",
    "#             break\n",
    "    \n",
    "#     species_cnt += 1\n",
    "    \n",
    "# print(species_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename = ebd_US_states_east_Mississippi_treswa_0101_0731_complete_zerofilled_grid_cells_relApr-2020.csv\n"
     ]
    }
   ],
   "source": [
    "# species = 'barswa'\n",
    "species = 'treswa'\n",
    "\n",
    "random_state = 1\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_grid_cells, df_julian_days_dates, df_cnt, df_grid_cells_days_dates, df_cnt_grid_cells_days_dates, \\\n",
    "df_min_cnt, df_cnt_zero, df_grid_cell, df_min_cnt_grid_cell, df_min_cnt_greater_than_grid_cell, \\\n",
    "df_min_cnt_greater_than_dates_grid_cell, df_grid_cell_date, df_sampled, df_cnt_sampled, df_sum_sampled, \\\n",
    "df_grp_sampled, df_grid_cells_threshold, df_cnt_not_sampled, df_sum_not_sampled, \\\n",
    "df_grp_not_sampled, df_grid_cells_days_dates_years, df_grp_sampled_dates, df_grp_not_sampled_dates, \\\n",
    "df_sum_prop_sampled, df_sum_prop_not_sampled, skip_species = name_of_function(\n",
    "    species, start_date, end_date, month, year, random_state, countries_states)\n",
    "\n",
    "# for random_state in range(1, 6):\n",
    "\n",
    "#     df_grid_cells, df_julian_days_dates, df_cnt, df_grid_cells_days_dates, df_cnt_grid_cells_days_dates, \\\n",
    "#     df_min_cnt, df_cnt_zero, df_grid_cell, df_min_cnt_grid_cell, df_min_cnt_greater_than_grid_cell, \\\n",
    "#     df_min_cnt_greater_than_dates_grid_cell, df_grid_cell_date, df_sampled, df_cnt_sampled, df_sum_sampled, \\\n",
    "#     df_grp_sampled, df_grid_cells_threshold, df_cnt_not_sampled, df_sum_not_sampled, \\\n",
    "#     df_grp_not_sampled, df_grid_cells_days_dates_years, df_grp_sampled_dates, df_grp_not_sampled_dates, \\\n",
    "#     df_sum_prop_sampled, df_sum_prop_not_sampled, skip_species = name_of_function(\n",
    "#         species, start_date, end_date, month, year, random_state, countries_states)\n",
    "\n",
    "print('(time.time() - start_time)/60 =', (time.time() - start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_cells.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_julian_days_dates.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnt.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_cells_days_dates.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cnt_grid_cells_days_dates.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_min_cnt.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnt_zero.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_cell.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min_cnt_grid_cell.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min_cnt_greater_than_grid_cell.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min_cnt_greater_than_dates_grid_cell.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_cell_date.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cnt_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sum_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_cells_threshold.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cnt_not_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sum_not_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp_not_sampled.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_cells_days_dates_years.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp_sampled_dates.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp_not_sampled_dates.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum_prop_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum_prop_not_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_grp_sampled['prop'].hist()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_grp_not_sampled['prop'].hist()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
