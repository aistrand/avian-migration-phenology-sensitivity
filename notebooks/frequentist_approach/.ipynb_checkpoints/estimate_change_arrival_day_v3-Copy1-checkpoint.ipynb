{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.regressionplots import abline_plot\n",
    "import geopandas\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/alvastrand/Documents/OU/Research/data/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '0101'\n",
    "end_date = '0731'\n",
    "month = 'Apr'\n",
    "year = '2020'\n",
    "countries_states = 'US_states_east_Mississippi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = 'output/'\n",
    "filename = 'obligate_aerial_insectivores_ebird_species_codes.csv'\n",
    "\n",
    "df = pd.read_csv(subdir + filename)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "      \n",
    "    print(i, df['species_code'].iloc[i], df['common_name'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_of_function(species, df, arrival_day_field_name, df_grid_cells, predictor_variable, *args):\n",
    "    \n",
    "    if (arrival_day_field_name == 'mean_arrival_day') | (arrival_day_field_name == 't_mad'):\n",
    "        \n",
    "        r_squared = args[0]\n",
    "        print('r_squared:', r_squared)\n",
    "        \n",
    "        # Filter\n",
    "        \n",
    "        df = df[df['r_squared'] >= r_squared]\n",
    "        print('len(df):', len(df))\n",
    "        \n",
    "        print(\"len(df['grid_cell'].unique()):\", len(df['grid_cell'].unique()))\n",
    "        \n",
    "    elif arrival_day_field_name == 'first_of_season_arrival_day':\n",
    "        \n",
    "        if args != ():\n",
    "            \n",
    "            random_state = args[0]\n",
    "        \n",
    "    if len(df) == 0:\n",
    "        \n",
    "        df_r = pd.DataFrame()\n",
    "        df_r_significant = pd.DataFrame()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df_cnt = df[['grid_cell', 'year']].groupby(['grid_cell']).count()\n",
    "        df_cnt = df_cnt.reset_index()\n",
    "        df_cnt = df_cnt.rename(columns={'year': 'nb_years'})\n",
    "        print('len(df_cnt):', len(df_cnt))\n",
    "        \n",
    "        cnt_years = 5\n",
    "                \n",
    "        # Filter\n",
    "\n",
    "        list_grid_cells = list(df_cnt[df_cnt['nb_years'] >= cnt_years]['grid_cell'])\n",
    "        \n",
    "        print('len(list_grid_cells):', len(list_grid_cells))\n",
    "        \n",
    "        if len(list_grid_cells) == 0:\n",
    "            \n",
    "            df_r = pd.DataFrame()\n",
    "            df_r_significant = pd.DataFrame()\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Filter\n",
    "\n",
    "            df = df[df['grid_cell'].isin(list_grid_cells)]\n",
    "            print('len(df):', len(df))\n",
    "\n",
    "            list_means_days = []\n",
    "            list_std_days = []\n",
    "#             list_days = []\n",
    "#             list_days_excluded = []\n",
    "            list_slopes_ols = []\n",
    "            list_intercepts_ols = []\n",
    "            list_p_values_ols = []\n",
    "            \n",
    "#             list_r_values = []\n",
    "#             list_std_err = []\n",
    "\n",
    "            for i in range(len(list_grid_cells)):\n",
    "        \n",
    "#                 print('list_grid_cells[i] =', list_grid_cells[i])\n",
    "                \n",
    "                df_subset = df[df['grid_cell'] == list_grid_cells[i]]\n",
    "                model_ols = smf.ols(formula=arrival_day_field_name + ' ~ ' + predictor_variable, data=df_subset)\n",
    "                res_ols = model_ols.fit()\n",
    "                \n",
    "#                 if (res_ols.params[1] > 5):\n",
    "                \n",
    "#                 print(res_ols.summary())\n",
    "\n",
    "#                 linregress = scipy.stats.linregress(df_subset[predictor_variable], \n",
    "#                                                     df_subset[arrival_day_field_name])\n",
    "#                 print(linregress)\n",
    "\n",
    "#####\n",
    "\n",
    "#                 if (species == 'barswa') & (np.absolute(res_ols.params.year) > 2):\n",
    "\n",
    "#                     print(species, np.absolute(res_ols.params.year))\n",
    "\n",
    "#     #                 plt.figure(figsize=(12.0, 4.0))\n",
    "#                     ax = df_subset.plot(x='year', y=arrival_day_field_name, kind='scatter')\n",
    "#     #                 plt.scatter(df_subset['year'], df_subset[arrival_day_field_name])\n",
    "#                     abline_plot(model_results=res_ols, ax=ax)\n",
    "\n",
    "#####\n",
    "\n",
    "#                 # plt.figure(figsize=(12.0, 4.0))\n",
    "\n",
    "#                 ax = df_subset.plot(x=predictor_variable, y=arrival_day_field_name, kind='scatter')\n",
    "\n",
    "#                 # plt.scatter(df_subset[predictor_variable], df_subset[arrival_day_field_name])\n",
    "\n",
    "#                 abline_plot(model_results=res_ols, ax=ax)\n",
    "\n",
    "#                 if (arrival_day_field_name == 'first_of_season_arrival_day') & (args != ()):\n",
    "\n",
    "#                         plt.title('Species code = ' + species + ', grid cell = ' + str(list_grid_cells[i]) + \\\n",
    "#                                   ', random state = ' + str(random_state))\n",
    "\n",
    "#                 else:\n",
    "\n",
    "#                         plt.title('Species code = ' + species + ', grid cell = ' + str(list_grid_cells[i]))\n",
    "\n",
    "#                 plt.show()\n",
    "\n",
    "                mean_day = df_subset[arrival_day_field_name].mean()\n",
    "                list_means_days.append(mean_day)\n",
    "                std_day = df_subset[arrival_day_field_name].std()\n",
    "                list_std_days.append(std_day)\n",
    "\n",
    "#                 df_subset['day_excluded'] = np.where(\n",
    "#                     (df_subset[arrival_day_field_name] > mean_day + 2*std_day) | \n",
    "#                     (df_subset[arrival_day_field_name] < mean_day - 2*std_day), 1, 0)\n",
    "#                 list_days.append(df_subset[[arrival_day_field_name, 'day_excluded']])\n",
    "\n",
    "#                 if 1 in list(df_subset['day_excluded']):\n",
    "#                     list_days_excluded.append(1)\n",
    "#                 else:\n",
    "#                     list_days_excluded.append(0)\n",
    "\n",
    "                list_slopes_ols.append(res_ols.params[1])\n",
    "                list_intercepts_ols.append(res_ols.params[0])\n",
    "                list_p_values_ols.append(res_ols.pvalues[1])\n",
    "\n",
    "#                 print(dir(res_ols))\n",
    "\n",
    "            df_r = pd.DataFrame(data={'grid_cell': list_grid_cells, 'slope_ols': list_slopes_ols, \n",
    "                                      'intercept_ols': list_intercepts_ols, 'p_value_ols': list_p_values_ols, \n",
    "                                      'mean_day': list_means_days, 'std_day': list_std_days})\n",
    "            \n",
    "            print('len(df_r) =', len(df_r))\n",
    "\n",
    "#             df_r = pd.DataFrame(data={'grid_cell': list_grid_cells, 'slope_ols': list_slopes_ols, \n",
    "#                                       'intercept_ols': list_intercepts_ols, 'mean_day': list_means_days, \n",
    "#                                       'std_day': list_std_days, 'day_excluded': list_days_excluded})\n",
    "\n",
    "            df_r = df_r.merge(df_grid_cells, on='grid_cell')\n",
    "            print('len(df_r) =', len(df_r))\n",
    "            \n",
    "#             print(\"len(df_r[df_r['p_value_ols'] <= 0.05]) =\", len(df_r[df_r['p_value_ols'] <= 0.05]))\n",
    "            \n",
    "            df_r_significant = df_r[df_r['p_value_ols'] <= 0.05]\n",
    "            print('len(df_r_significant) =', len(df_r_significant))\n",
    "            \n",
    "            # Filter\n",
    "\n",
    "#             df_r = df_r[df_r['day_excluded'] == 0]\n",
    "#             print('len(df_r):', len(df_r))\n",
    "\n",
    "            df_r['lat_band'] = np.nan\n",
    "\n",
    "            list_lat_band_boundaries = range(20, 55, 5)\n",
    "\n",
    "            for i in range(len(list_lat_band_boundaries)):\n",
    "\n",
    "                if i == len(list_lat_band_boundaries) - 1:\n",
    "                    bounding_lat = list_lat_band_boundaries[i] + 5\n",
    "                else:\n",
    "                    bounding_lat = list_lat_band_boundaries[i+1]\n",
    "\n",
    "                df_r.loc[(df_r['min_lat'] > list_lat_band_boundaries[i]) & \n",
    "                     (df_r['min_lat'] <= bounding_lat), 'lat_band'] = bounding_lat\n",
    "\n",
    "            df_r['lat_band'] = df_r['lat_band'].astype(int)\n",
    "\n",
    "            list_lat_bands = list(df_r['lat_band'].unique())\n",
    "\n",
    "#             for i in range(len(list_lat_bands)):\n",
    "\n",
    "#                 print('list_lat_bands[i]:', list_lat_bands[i])\n",
    "\n",
    "#                 df_subset = df_r[df_r['lat_band'] == list_lat_bands[i]]\n",
    "\n",
    "#                 print(\"df_subset['slope_ols'].mean():\", df_subset['slope_ols'].mean())\n",
    "#                 print(\"df_subset['slope_ols'].median():\", df_subset['slope_ols'].median())\n",
    "#                 print(df_subset['slope_ols'].std())\n",
    "\n",
    "#             print(\"scipy.stats.linregress(df_r['min_lat'], df_r['slope_ols']):\", \n",
    "#                   scipy.stats.linregress(df_r['min_lat'], df_r['slope_ols']))\n",
    "#             print(\"scipy.stats.linregress(df_r['max_lat'], df_r['slope_ols']):\", \n",
    "#                   scipy.stats.linregress(df_r['max_lat'], df_r['slope_ols']))\n",
    "#             print(\"scipy.stats.linregress(df_r['min_lon'], df_r['slope_ols']):\", \n",
    "#                   scipy.stats.linregress(df_r['min_lon'], df_r['slope_ols']))\n",
    "#             print(\"scipy.stats.linregress(df_r['max_lon'], df_r['slope_ols']):\", \n",
    "#                   scipy.stats.linregress(df_r['max_lon'], df_r['slope_ols']))\n",
    "\n",
    "#             plt.scatter(df_r['min_lat'], df_r['slope_ols'])\n",
    "#             plt.show()\n",
    "\n",
    "#             plt.scatter(df_r['max_lat'], df_r['slope_ols'])\n",
    "#             plt.show()\n",
    "\n",
    "#             plt.scatter(df_r['min_lon'], df_r['slope_ols'])\n",
    "#             plt.show()\n",
    "\n",
    "#             plt.scatter(df_r['max_lon'], df_r['slope_ols'])\n",
    "#             plt.show()\n",
    "\n",
    "            \n",
    "            assert(len(df_r['grid_cell'].unique()) == len(df_r))\n",
    "\n",
    "\n",
    "            # df_days_year = df[['grid_cell', 'year', arrival_day_field_name]].merge(df_r, on=['grid_cell'])\n",
    "\n",
    "            # plt.scatter(df_days_year['year'], df_days_year[arrival_day_field_name])\n",
    "            # plt.xlabel('Year')\n",
    "            # plt.show()\n",
    "\n",
    "#             print(\"scipy.stats.linregress(df_days_year['year'], df_days_year[arrival_day_field_name]):\", \n",
    "#                   scipy.stats.linregress(df_days_year['year'], df_days_year[arrival_day_field_name]))\n",
    "\n",
    "            df_r['mean_lat'] = (df_r['min_lat'] + df_r['max_lat'])/2\n",
    "            df_r['mean_lon'] = (df_r['min_lon'] + df_r['max_lon'])/2\n",
    "\n",
    "            # df_r['abs_slope'] = df_r['slope_ols'].abs()*100\n",
    "\n",
    "#             df_g = geopandas.GeoDataFrame(\n",
    "#                 df_r, geometry=geopandas.points_from_xy(df_r['mean_lon'], df_r['mean_lat']))\n",
    "\n",
    "#             print(\"df_g['slope_ols'].min():\", df_g['slope_ols'].min())\n",
    "#             print(\"np.floor(df_g['slope_ols'].min()):\", np.floor(df_g['slope_ols'].min()))\n",
    "#             print(\"df_g['slope_ols'].max():\", df_g['slope_ols'].max())\n",
    "#             print(\"np.ceil(df_g['slope_ols'].max()):\", np.ceil(df_g['slope_ols'].max()))\n",
    "\n",
    "#             abs_floor_min_slope = np.absolute(np.floor(df_g['slope_ols'].min()))\n",
    "#             abs_ceil_max_slope = np.absolute(np.ceil(df_g['slope_ols'].max()))\n",
    "\n",
    "#             print('abs_floor_min_slope:', abs_floor_min_slope)\n",
    "#             print('abs_ceil_max_slope:', abs_ceil_max_slope)\n",
    "\n",
    "#             greatest_abs = max([abs_floor_min_slope, abs_ceil_max_slope])\n",
    "\n",
    "#             v_min = -greatest_abs\n",
    "#             v_max = greatest_abs\n",
    "            \n",
    "#             norm = matplotlib.colors.Normalize(vmin=v_min, vmax=v_max)\n",
    "            \n",
    "#             matplotlib.rcParams['font.size'] = 15\n",
    "            \n",
    "#             world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "            \n",
    "#             ax = world[world['iso_a3'] == 'USA'].plot(\n",
    "#                 color='white', edgecolor='black', figsize=(20.0, 15.0))\n",
    "\n",
    "#             sc = plt.scatter('mean_lon', 'mean_lat', s=250, c='slope_ols', alpha=0.5, cmap='RdBu_r', data=df_g, \n",
    "#                              norm=norm, edgecolor='black', marker='o')\n",
    "#             # sc = plt.scatter(\n",
    "#             #     'mean_lon', 'mean_lat', s='abs_slope', c='slope_ols', alpha=0.5, cmap='RdBu', data=df_g)\n",
    "#             # plt.colorbar(sc, cax=ax)\n",
    "#             plt.colorbar(sc, fraction=0.0241, pad=0.015)\n",
    "#             plt.xlabel('Longitude')\n",
    "#             plt.ylabel('Latitude')\n",
    "#             plt.title(\n",
    "#                 'Slopes of mean arrival date as a function of time shown as bubbles on a map of the United \\\n",
    "#                 States')\n",
    "#             plt.show()\n",
    "\n",
    "            # world[world['iso_a3'] == 'USA']\n",
    "\n",
    "    return df_r, df_r_significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes(species, df, arrival_day_field_name, df_grid_cells, r_squared, list_df_mean, \n",
    "                   list_df_mean_significant, predictor_variable):\n",
    "    \n",
    "    df_r_mean, df_r_mean_significant = name_of_function(species, df, arrival_day_field_name, df_grid_cells, \n",
    "                                                        predictor_variable, r_squared)\n",
    "    \n",
    "    \n",
    "    if len(df_r_mean) == 0:\n",
    "        \n",
    "        list_df_mean.append(pd.DataFrame())\n",
    "#         list_df_r_comp.append(pd.DataFrame())\n",
    "        \n",
    "    else:\n",
    "        \n",
    "#         df_r_mean = df_r_mean.rename(columns={'slope': 'slope_mean'})\n",
    "        df_r_mean['species_code'] = species\n",
    "\n",
    "#         df_r_comp = df_r_first_of[['grid_cell', 'slope_first_of_season', 'species_code']].merge(\n",
    "#             df_r_mean[['grid_cell', 'slope_mean', 'species_code']], on=['grid_cell', 'species_code'])\n",
    "\n",
    "        print('len(df_r_mean):', len(df_r_mean))\n",
    "#         print('len(df_r_comp):', len(df_r_comp))\n",
    "        \n",
    "#         print(\"len(df_r_comp['slope_mean']):\", len(df_r_comp['slope_mean']))\n",
    "\n",
    "#         if len(df_r_comp) > 0:\n",
    "#             df_r_comp.plot('slope_mean', 'slope_first_of_season', kind='scatter')\n",
    "#             plt.show()\n",
    "\n",
    "        list_df_mean.append(df_r_mean)\n",
    "#         list_df_r_comp.append(df_r_comp)\n",
    "\n",
    "\n",
    "    if len(df_r_mean_significant) == 0:\n",
    "        \n",
    "        list_df_mean_significant.append(pd.DataFrame())\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df_r_mean_significant['species_code'] = species\n",
    "\n",
    "        print('len(df_r_mean_significant):', len(df_r_mean_significant))        \n",
    "\n",
    "        list_df_mean_significant.append(df_r_mean_significant)\n",
    "        \n",
    "        \n",
    "    return list_df_mean, list_df_mean_significant\n",
    "\n",
    "#     return list_df_mean, list_df_r_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(species, start_date, end_date, start_year, end_year, month, year, predictor_variable, *args):\n",
    "    \n",
    "    subdir = 'eBird/ebd_output/'\n",
    "\n",
    "    if args != ():\n",
    "\n",
    "        countries_states = args[0]\n",
    "        \n",
    "        filename_first_of_season = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + \\\n",
    "        end_date + '_complete_zerofilled_grid_cells_proportions_first_of_season_rel' + month + '-' + year + \\\n",
    "        '_v2.csv'\n",
    "        print('filename_first_of_season =', filename_first_of_season)\n",
    "        \n",
    "        filename_mean = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "        '_complete_zerofilled_grid_cells_proportions_mean_rel' + month + '-' + year + '.csv'\n",
    "        print('filename_mean =', filename_mean)\n",
    "        \n",
    "        filename_grid_cell_ids = 'ebd_' + countries_states + '_' + start_date + '_' + end_date + \\\n",
    "        '_complete_zerofilled_grid_cell_ids_rel' + month + '-' + year + '.csv'\n",
    "        print('filename_grid_cell_ids =', filename_grid_cell_ids)\n",
    "        \n",
    "#####\n",
    "\n",
    "        # Sampling\n",
    "\n",
    "        if len(args) > 1:\n",
    "        \n",
    "            sampled = args[1]\n",
    "            \n",
    "#             grid_cell = 117\n",
    "#             grid_cell = 147\n",
    "#             grid_cell = 151\n",
    "        \n",
    "            if sampled == 1:\n",
    "\n",
    "                string = 'sampled'\n",
    "\n",
    "                random_state = args[2]\n",
    "\n",
    "                # Incorrect!\n",
    "\n",
    "                filename_first_of_season = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + \\\n",
    "                end_date + '_' + actual_start_date + '_' + actual_end_date + \\\n",
    "                '_complete_zerofilled_grid_cells_proportions_first_of_season_' + str(start_year) + '_' + \\\n",
    "                str(end_year) + '_' + string + '_' + str(random_state) + '_rel' + month + '-' + year + '.csv'\n",
    "                print('filename_first_of_season =', filename_first_of_season)\n",
    "\n",
    "#                 filename_first_of_season = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + \\\n",
    "#                 end_date + '_complete_zerofilled_grid_cells_proportions_first_of_season_' + str(start_year) + \\\n",
    "#                 '_' + str(end_year) + '_' + string + '_' + str(random_state) + '_rel' + month + '-' + year + \\\n",
    "#                 '.csv'\n",
    "#                 print('filename_first_of_season =', filename_first_of_season)\n",
    "\n",
    "                # A single grid cell\n",
    "\n",
    "#                 filename_mean = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "#                 '_complete_zerofilled_grid_cell_' + str(grid_cell) + '_proportions_mean_' + str(start_year) + \\\n",
    "#                 '_' + str(end_year) + '_' + string + '_' + str(random_state) + '_rel' + month + '-' + year + \\\n",
    "#                 '.csv'\n",
    "#                 print('filename_mean =', filename_mean)\n",
    "\n",
    "            elif sampled == 0:\n",
    "\n",
    "                string = 'not_sampled'\n",
    "\n",
    "                # Incorrect!\n",
    "\n",
    "                filename_first_of_season = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + \\\n",
    "                end_date + '_' + actual_start_date + '_' + actual_end_date + \\\n",
    "                '_complete_zerofilled_grid_cells_proportions_first_of_season_' + str(start_year) + '_' + \\\n",
    "                str(end_year) + '_' + string + '_rel' + month + '-' + year + '.csv'\n",
    "                print('filename_first_of_season =', filename_first_of_season)\n",
    "\n",
    "#                 filename_first_of_season = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + \\\n",
    "#                 end_date + '_complete_zerofilled_grid_cells_proportions_first_of_season_' + str(start_year) + \\\n",
    "#                 '_' + str(end_year) + '_' + string + '_rel' + month + '-' + year + '.csv'\n",
    "#                 print('filename_first_of_season =', filename_first_of_season)\n",
    "\n",
    "                # A single grid cell\n",
    "    \n",
    "#                 filename_mean = 'ebd_' + countries_states + '_' + species + '_' + start_date + '_' + end_date + \\\n",
    "#                 '_complete_zerofilled_grid_cell_' + str(grid_cell) + '_proportions_mean_' + str(start_year) + \\\n",
    "#                 '_' + str(end_year) + '_' + string + '_rel' + month + '-' + year + '.csv'\n",
    "#                 print('filename_mean =', filename_mean)\n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "    # Mean arrival day\n",
    "\n",
    "    df = pd.read_csv(subdir + filename_mean)\n",
    "    df['mad'] = pd.to_datetime(df['mad'])\n",
    "#     df['mean_arrival_date'] = pd.to_datetime(df['mean_arrival_date'])\n",
    "    print('len(df):', len(df))\n",
    "    print(\"len(df['grid_cell'].unique()):\", len(df['grid_cell'].unique()))\n",
    "    \n",
    "    # Filter\n",
    "    \n",
    "    df = df[df['year'] >= 2002]\n",
    "    print('len(df):', len(df))\n",
    "    print(\"len(df['grid_cell'].unique()):\", len(df['grid_cell'].unique()))\n",
    "    \n",
    "    # Filter\n",
    "    \n",
    "    df = df[df['year'] != 2020]\n",
    "    print('len(df):', len(df))\n",
    "    print(\"len(df['grid_cell'].unique()):\", len(df['grid_cell'].unique()))\n",
    "    \n",
    "    \n",
    "    # First-of-season arrival day\n",
    "    \n",
    "    df_first_of = pd.read_csv(subdir + filename_first_of_season)\n",
    "    df_first_of['first_of_season_arrival_date'] = pd.to_datetime(df_first_of['first_of_season_arrival_date'])\n",
    "    df_first_of['first_of_season_arrival_day'] = df_first_of['first_of_season_arrival_day'].astype('int')\n",
    "    print('len(df_first_of):', len(df_first_of))\n",
    "\n",
    "    \n",
    "    df_grid_cells = pd.read_csv(subdir + filename_grid_cell_ids)\n",
    "    print('len(df_grid_cells):', len(df_grid_cells))\n",
    "    # 182?\n",
    "    \n",
    "    \n",
    "    print(\"len(df_first_of['grid_cell'].unique()):\", len(df_first_of['grid_cell'].unique()))\n",
    "    \n",
    "    \n",
    "    if predictor_variable == 'air_temp_degrees_celsius':\n",
    "        \n",
    "        start_year_narr = 2002\n",
    "        end_year_narr = 2019\n",
    "\n",
    "        subdir = 'output/'\n",
    "\n",
    "        filename = 'ncep_narr_air_2m_ebd_' + countries_states + '_' + start_date + '_' + end_date + \\\n",
    "        '_complete_zerofilled_grid_cell_ids_' + str(start_year_narr) + '_' + str(end_year_narr) + '_rel' + \\\n",
    "        month + '-' + year + '.csv'\n",
    "        \n",
    "        df_grid_cells_years_air_temps = pd.read_csv(subdir + filename)\n",
    "\n",
    "        print(len(df_grid_cells_years_air_temps))\n",
    "        \n",
    "        df_first_of = df_first_of.merge(\n",
    "            df_grid_cells_years_air_temps[['grid_cell', 'year', 'air_temp_degrees_celsius']], \n",
    "            on=['grid_cell', 'year'])\n",
    "        \n",
    "        print('len(df_first_of) =', len(df_first_of))\n",
    "        \n",
    "        df = df.merge(df_grid_cells_years_air_temps[['grid_cell', 'year', 'air_temp_degrees_celsius']], \n",
    "                      on=['grid_cell', 'year'])\n",
    "        \n",
    "        print('len(df) =', len(df))\n",
    "\n",
    "\n",
    "#     df_comp = df.merge(df_first_of, on=['grid_cell', 'year'])\n",
    "\n",
    "#     df_comp.plot('t_mad', 'first_of_season_arrival_day', kind='scatter')\n",
    "#     plt.show()\n",
    "\n",
    "#     print(\"df['r_squared'].mean():\", df['r_squared'].mean())\n",
    "#     print(\"df['r_squared'].std():\", df['r_squared'].std())\n",
    "#     print(\"df['r_squared'].median():\", df['r_squared'].median())\n",
    "#     print(\"df['r_squared'].min():\", df['r_squared'].min())\n",
    "#     print(\"df['r_squared'].max():\", df['r_squared'].max())\n",
    "\n",
    "\n",
    "    arrival_day_field_name = 'first_of_season_arrival_day'\n",
    "    \n",
    "    df_r_first_of, df_r_first_of_significant = name_of_function(species, df_first_of, arrival_day_field_name, \n",
    "                                                                df_grid_cells, predictor_variable)\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "    # Sampling\n",
    "    \n",
    "#     if sampled == 1:\n",
    "            \n",
    "#         df_r_first_of = name_of_function(species, df_first_of, arrival_day_field_name, df_grid_cells, \n",
    "#                                          predictor_variable, random_state)\n",
    "    \n",
    "#     elif sampled == 0:\n",
    "        \n",
    "#         df_r_first_of = name_of_function(species, df_first_of, arrival_day_field_name, df_grid_cells, \n",
    "#                                          predictor_variable)\n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "    df_r_first_of = df_r_first_of.rename(columns={'slope_ols': 'slope_first_of_season_ols'})\n",
    "    df_r_first_of['species_code'] = species\n",
    "    print('len(df_r_first_of):', len(df_r_first_of))\n",
    "    \n",
    "    df_r_first_of_significant = df_r_first_of_significant.rename(\n",
    "        columns={'slope_ols': 'slope_first_of_season_ols'})\n",
    "    df_r_first_of_significant['species_code'] = species\n",
    "    print('len(df_r_first_of_significant):', len(df_r_first_of_significant))\n",
    "    \n",
    "    \n",
    "    # Mean arrival day\n",
    "\n",
    "    list_df_r_mean = []\n",
    "    list_df_r_mean_significant = []\n",
    "#     list_df_r_comp = []\n",
    "    \n",
    "#     arrival_day_field_name = 'mean_arrival_day'\n",
    "    arrival_day_field_name = 't_mad'\n",
    "\n",
    "    r_squared = 0.1\n",
    "    print('r_squared:', r_squared)\n",
    "    \n",
    "    list_df_r_mean, list_df_r_mean_significant = get_dataframes(\n",
    "        species, df, arrival_day_field_name, df_grid_cells, r_squared, list_df_r_mean, \n",
    "        list_df_r_mean_significant, predictor_variable)\n",
    "    \n",
    "    r_squared = 0.5\n",
    "    print('r_squared:', r_squared)\n",
    "    \n",
    "    list_df_r_mean, list_df_r_mean_significant = get_dataframes(\n",
    "        species, df, arrival_day_field_name, df_grid_cells, r_squared, list_df_r_mean, \n",
    "        list_df_r_mean_significant, predictor_variable)\n",
    "\n",
    "#     r_squared = 0.7\n",
    "    r_squared = 0.8\n",
    "    print('r_squared:', r_squared)\n",
    "    \n",
    "    list_df_r_mean, list_df_r_mean_significant = get_dataframes(\n",
    "        species, df, arrival_day_field_name, df_grid_cells, r_squared, list_df_r_mean, \n",
    "        list_df_r_mean_significant, predictor_variable)\n",
    "\n",
    "\n",
    "    return df, df_first_of, df_grid_cells, df_r_first_of, \\\n",
    "df_r_first_of_significant, list_df_r_mean, list_df_r_mean_significant\n",
    "\n",
    "#     return df, df_first_of, df_grid_cells, df_grid_cells_years_air_temps, df_r_first_of, \\\n",
    "# df_r_first_of_significant, list_df_r_mean, list_df_r_mean_significant\n",
    "\n",
    "# list_df_r_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# species = 'treswa'\n",
    "# # species = 'barswa'\n",
    "# print(species)\n",
    "\n",
    "# # first_year = 2002\n",
    "# first_year = 2003\n",
    "\n",
    "# # start_year = '2002'\n",
    "\n",
    "# # start_year = '2015'\n",
    "# # start_year = '2014'\n",
    "\n",
    "# end_year = 2019\n",
    "\n",
    "# actual_start_date = '0101'\n",
    "# actual_end_date = '0630'\n",
    "\n",
    "# sampled = 1\n",
    "\n",
    "# random_state = 1\n",
    "\n",
    "# # df_first_of_species = pd.DataFrame()\n",
    "\n",
    "# # df_mean_min_r_squared_species = pd.DataFrame()\n",
    "# # df_mean_mean_r_squared_species = pd.DataFrame()\n",
    "\n",
    "# # df_mean_std_mean_r_squared_species = pd.DataFrame()\n",
    "\n",
    "###\n",
    "\n",
    "# # df_mean, df_grid_cells, list_df_r_mean = main_function(\n",
    "# #     species, start_date, end_date, start_year, end_year, month, year, sampled, countries_states, random_state)\n",
    "\n",
    "            \n",
    "# # if len(list_df_r_mean[0]) > 0:\n",
    "\n",
    "# #     df_mean_min_r_squared_species = df_mean_min_r_squared_species.append(list_df_r_mean[0])\n",
    "\n",
    "# # if len(list_df_r_mean[1]) > 0:\n",
    "\n",
    "# #     df_mean_mean_r_squared_species = df_mean_mean_r_squared_species.append(list_df_r_mean[1])\n",
    "\n",
    "# # if len(list_df_r_mean[2]) > 0:\n",
    "\n",
    "# #     df_mean_std_mean_r_squared_species = df_mean_std_mean_r_squared_species.append(list_df_r_mean[2])\n",
    "\n",
    "\n",
    "# # if len(list_df_r_mean[0]) > 0:\n",
    "\n",
    "# #     df_mean_std_mean_r_squared_species = df_mean_std_mean_r_squared_species.append(list_df_r_mean[0])\n",
    "\n",
    "\n",
    "# df_r_first_of_sampled_years = pd.DataFrame()\n",
    "\n",
    "# for start_year in range(first_year, end_year + 1):\n",
    "# # for start_year in range(first_year, first_year + 2):\n",
    "\n",
    "#     # start_year = 2003\n",
    "\n",
    "#     start_year = str(start_year)\n",
    "#     print('start_year =', start_year)\n",
    "\n",
    "###\n",
    "\n",
    "#     df_first_of_sampled, df_grid_cells_sampled, df_r_first_of_sampled = main_function(\n",
    "#         species, start_date, end_date, start_year, end_year, month, year, sampled, countries_states, \n",
    "#         random_state)\n",
    "\n",
    "#     df_first_of_sampled['first_year'] = start_year\n",
    "#     df_r_first_of_sampled['first_year'] = start_year\n",
    "\n",
    "#     df_r_first_of_sampled_years = df_r_first_of_sampled_years.append(df_r_first_of_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled = 0\n",
    "\n",
    "# # df_first_of_species = pd.DataFrame()\n",
    "\n",
    "# # df_mean_std_mean_r_squared_species_not_sampled = pd.DataFrame()\n",
    "\n",
    "###\n",
    "\n",
    "# # df_mean_not_sampled, df_grid_cells_not_sampled, list_df_r_mean_not_sampled = main_function(\n",
    "# #     species, start_date, end_date, start_year, end_year, month, year, sampled, countries_states, random_state)\n",
    "\n",
    "# # if len(list_df_r_mean_not_sampled[0]) > 0:\n",
    "\n",
    "# #     df_mean_std_mean_r_squared_species_not_sampled = df_mean_std_mean_r_squared_species_not_sampled.append(\n",
    "# #         list_df_r_mean_not_sampled[0])\n",
    "\n",
    "\n",
    "# df_r_first_of_not_sampled_years = pd.DataFrame()\n",
    "\n",
    "# for start_year in range(first_year, end_year + 1):\n",
    "# # for start_year in range(first_year, first_year + 2):\n",
    "\n",
    "#     # start_year = 2003\n",
    "\n",
    "#     start_year = str(start_year)\n",
    "#     print('start_year =', start_year)\n",
    "\n",
    "###\n",
    "    \n",
    "#     df_first_of_not_sampled, df_grid_cells_not_sampled, df_r_first_of_not_sampled = main_function(\n",
    "#         species, start_date, end_date, start_year, end_year, month, year, sampled, countries_states)\n",
    "\n",
    "#     df_first_of_not_sampled['first_year'] = start_year\n",
    "#     df_r_first_of_not_sampled['first_year'] = start_year\n",
    "\n",
    "#     df_r_first_of_not_sampled_years = df_r_first_of_not_sampled_years.append(df_r_first_of_not_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_first_of_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r_first_of_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r_first_of_sampled_years.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_first_of_not_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r_first_of_not_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r_first_of_not_sampled_years.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_r_first_of_sampled_years = df_r_first_of_sampled_years.rename(\n",
    "#     columns={'slope_first_of_season_ols': 'slope_first_of_season_ols_sampled', \n",
    "#              'intercept_ols': 'intercept_ols_sampled', 'mean_day': 'mean_day_sampled', \n",
    "#              'std_day': 'std_day_sampled'})\n",
    "\n",
    "# df_r_first_of_not_sampled_years = df_r_first_of_not_sampled_years.rename(\n",
    "#     columns={'slope_first_of_season_ols': 'slope_first_of_season_ols_not_sampled', \n",
    "#              'intercept_ols': 'intercept_ols_not_sampled', 'mean_day': 'mean_day_not_sampled', \n",
    "#              'std_day': 'std_day_not_sampled'})\n",
    "\n",
    "# df_r_first_of_sampled_not_sampled_years = df_r_first_of_not_sampled_years.merge(\n",
    "#     df_r_first_of_sampled_years, on=['grid_cell', 'min_lat', 'max_lat', 'min_lon', 'max_lon', 'lat_band',\n",
    "#                                      'mean_lat', 'mean_lon', 'species_code', 'first_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_r_first_of_sampled_not_sampled_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for start_year in range(first_year, end_year + 1):\n",
    "# # for start_year in range(first_year, first_year + 2):\n",
    "    \n",
    "#     print('start_year =', start_year)\n",
    "    \n",
    "#     df_r_first_of_sampled_not_sampled_years[\n",
    "#         df_r_first_of_sampled_not_sampled_years['first_year'] == str(start_year)].plot(\n",
    "#         'slope_first_of_season_ols_not_sampled', 'slope_first_of_season_ols_sampled', kind='scatter')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_year = '2002'\n",
    "end_year = '2019'\n",
    "\n",
    "predictor_variable = 'year'\n",
    "# predictor_variable = 'air_temp_degrees_celsius'\n",
    "\n",
    "# sampled = 1\n",
    "\n",
    "# random_state = 1\n",
    "\n",
    "#####\n",
    "\n",
    "# Test\n",
    "\n",
    "species = 'treswa'\n",
    "\n",
    "# df_mean, df_first_of, df_grid_cells, df_r_first_of, df_r_first_of_significant, \\\n",
    "# list_df_r_mean, list_df_r_mean_significant = main_function(\n",
    "#     species, start_date, end_date, start_year, end_year, month, year, predictor_variable, countries_states)\n",
    "\n",
    "# df_mean, df_first_of, df_grid_cells, df_grid_cells_years_air_temps, df_r_first_of, df_r_first_of_significant, \\\n",
    "# list_df_r_mean, list_df_r_mean_significant = main_function(\n",
    "#     species, start_date, end_date, start_year, end_year, month, year, predictor_variable, countries_states)\n",
    "\n",
    "#####\n",
    "\n",
    "df_first_of_species = pd.DataFrame()\n",
    "df_mean_min_r_squared_species = pd.DataFrame()\n",
    "df_mean_mean_r_squared_species = pd.DataFrame()\n",
    "df_mean_std_mean_r_squared_species = pd.DataFrame()\n",
    "\n",
    "species_cnt = 0\n",
    "\n",
    "# For each species\n",
    "\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    print(i)\n",
    "  \n",
    "    species = df['species_code'].iloc[i]\n",
    "    print(species)\n",
    "    \n",
    "    if ((species == 'souwpw1') | (species == 'bucnig') | (species == 'compoo') | (species == 'whtswi') | \n",
    "        (species == \"blkswi\") | (species == 'vigswa')):\n",
    "        continue\n",
    "    \n",
    "    df_mean, df_first_of, df_grid_cells, df_r_first_of, \\\n",
    "    df_r_first_of_significant, list_df_r_mean, list_df_r_mean_significant = main_function(\n",
    "        species, start_date, end_date, start_year, end_year, month, year, predictor_variable, countries_states)\n",
    "    \n",
    "#     df_mean, df_first_of, df_grid_cells, df_grid_cells_years_air_temps, df_r_first_of, \\\n",
    "#     df_r_first_of_significant, list_df_r_mean, list_df_r_mean_significant = main_function(\n",
    "#         species, start_date, end_date, start_year, end_year, month, year, predictor_variable, countries_states)\n",
    "\n",
    "    \n",
    "    # Sampling\n",
    "    \n",
    "#     df_mean, df_grid_cells, list_df_r_mean = main_function(\n",
    "#         species, start_date, end_date, start_year, end_year, month, year, predictor_variable, \n",
    "#         countries_states, sampled, random_state)\n",
    "\n",
    "\n",
    "    # list_df_r_comp!\n",
    "    \n",
    "#     df_mean, df_first_of, df_grid_cells, df_grid_cells_years_air_temps, df_r_first_of, \\\n",
    "#     df_r_first_of_significant, list_df_r_mean, list_df_r_mean_significant, list_df_r_comp = main_function(\n",
    "#         species, start_date, end_date, start_year, end_year, month, year, predictor_variable, countries_states)\n",
    "\n",
    "    \n",
    "    if len(df_r_first_of) > 0:\n",
    "        \n",
    "        df_first_of_species = df_first_of_species.append(df_r_first_of)\n",
    "            \n",
    "    if len(list_df_r_mean[0]) > 0:\n",
    "\n",
    "        df_mean_min_r_squared_species = df_mean_min_r_squared_species.append(list_df_r_mean[0])\n",
    "            \n",
    "    if len(list_df_r_mean[1]) > 0:\n",
    "\n",
    "        df_mean_mean_r_squared_species = df_mean_mean_r_squared_species.append(list_df_r_mean[1])\n",
    "            \n",
    "    if len(list_df_r_mean[2]) > 0:\n",
    "\n",
    "        df_mean_std_mean_r_squared_species = df_mean_std_mean_r_squared_species.append(list_df_r_mean[2])\n",
    "\n",
    "\n",
    "#     if len(list_df_r_mean[0]) > 0:\n",
    "\n",
    "#         df_mean_std_mean_r_squared_species = df_mean_std_mean_r_squared_species.append(list_df_r_mean[0])\n",
    "\n",
    "    \n",
    "    species_cnt += 1\n",
    "\n",
    "print(species_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_of.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_first_of.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_df_r_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mean_not_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list_df_r_mean_not_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_first_of_species))\n",
    "print(len(df_mean_min_r_squared_species))\n",
    "print(len(df_mean_mean_r_squared_species))\n",
    "print(len(df_mean_std_mean_r_squared_species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df_mean_std_mean_r_squared_species_not_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_of_species.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_min_r_squared_species.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_mean_r_squared_species.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_std_mean_r_squared_species.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mean_std_mean_r_squared_species_not_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = 'output/'\n",
    "filename = 'all_obligate_aerial_insectivores_ebirdst_weighted_mean_body_masses.csv'\n",
    "\n",
    "df_o_a_i_masses = pd.read_csv(subdir + filename)\n",
    "\n",
    "print(len(df_o_a_i_masses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o_a_i_masses.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = 'output/'\n",
    "filename = 'obligate_aerial_insectivores_birdlife_nacc_north_america_handbook_added.csv'\n",
    "\n",
    "df_a_i_na_h_added = pd.read_csv(subdir + filename)\n",
    "\n",
    "print(len(df_a_i_na_h_added))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_i_na_h_added.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slopes(df_species, field_name, predictor_variable):\n",
    "\n",
    "    df_merged = df_species.merge(df[['scientific_name', 'common_name', 'species_code']], on=['species_code'])\n",
    "    \n",
    "    len_df_merged_before = len(df_merged)\n",
    "    print('len_df_merged_before =', len_df_merged_before)\n",
    "\n",
    "    df_merged = df_merged.merge(df_o_a_i_masses, on=['scientific_name', 'common_name', 'species_code'])\n",
    "    \n",
    "    assert(len(df_merged) == len_df_merged_before)\n",
    "    \n",
    "    df_merged['body_mass_mg'] = df_merged['body_mass']*1000\n",
    "    df_merged['log_body_mass_mg'] = np.log(df_merged['body_mass_mg'])\n",
    "    \n",
    "    print(\"len(df_merged['species_code'].unique()) =\", len(df_merged['species_code'].unique()))\n",
    "    \n",
    "    color_values = matplotlib.cm.rainbow(np.linspace(0, 1, len(df_merged['species_code'].unique())))\n",
    "    colors = dict(zip(df_merged['species_code'].unique(), color_values))\n",
    "    \n",
    "    body_mass_field_name = 'log_body_mass_mg'\n",
    "#     body_mass_field_name = 'body_mass_mg'\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for species in list(df_merged['species_code'].unique()):\n",
    "        \n",
    "        df_subset = df_merged[df_merged['species_code'] == species]\n",
    "        \n",
    "        df_subset.plot(ax=ax, kind='scatter', x=body_mass_field_name, y=field_name, label=species, \n",
    "                       color=colors[species], figsize=(15,10))\n",
    "        \n",
    "#         df_subset.plot(ax=ax, kind='scatter', x=body_mass_field_name, y=field_name, label=species, \n",
    "#                        color=colors[species], figsize=(15,10), s=df_subset['lat_band'])\n",
    "\n",
    "#     plt.scatter(df_merged[body_mass_field_name], df_merged[field_name], \n",
    "#                 c=df_merged['species_code'].apply(lambda x: colors[x]), s=df_merged['lat_band'])\n",
    "\n",
    "#     plt.scatter(df_merged[body_mass_field_name], df_merged[field_name], \n",
    "#                 c=df_merged['species_code'].apply(lambda x: colors[x]), label=df_merged['species_code'], \n",
    "#                 s='lat_band')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.axhline(y=0, color='r', linestyle='-')\n",
    "    plt.xlabel('Natural logarithm of body mass (mg)')\n",
    "    plt.ylabel('Slope of arrival day as a function of ' + predictor_variable)\n",
    "    plt.show()\n",
    "    \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_of_species_significant = df_first_of_species[df_first_of_species['p_value_ols'] <= 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('len(df_first_of_species_significant) =', len(df_first_of_species_significant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_of_species_significant.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'slope_first_of_season_ols'\n",
    "df_first_of_species_merged = plot_slopes(df_first_of_species, field_name, predictor_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'slope_first_of_season_ols'\n",
    "df_first_of_species_merged = plot_slopes(df_first_of_species_significant, field_name, predictor_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_first_of_species.plot('min_lat', 'slope_first_of_season_ols', kind='scatter')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_first_of_species[df_first_of_species['species_code'] == 'purmar'].sort_values(by='slope_first_of_season', \n",
    "#                                                                                  ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_min_r_squared_species_significant = df_mean_min_r_squared_species[\n",
    "    df_mean_min_r_squared_species['p_value_ols'] <= 0.05]\n",
    "df_mean_mean_r_squared_species_significant = df_mean_mean_r_squared_species[\n",
    "    df_mean_mean_r_squared_species['p_value_ols'] <= 0.05]\n",
    "df_mean_std_mean_r_squared_species_significant = df_mean_std_mean_r_squared_species[\n",
    "    df_mean_std_mean_r_squared_species['p_value_ols'] <= 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('len(df_mean_min_r_squared_species_significant) =', len(df_mean_min_r_squared_species_significant))\n",
    "print('len(df_mean_mean_r_squared_species_significant) =', len(df_mean_mean_r_squared_species_significant))\n",
    "print('len(df_mean_std_mean_r_squared_species_significant) =', len(df_mean_std_mean_r_squared_species_significant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_min_r_squared_species_significant.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_mean_r_squared_species_significant.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_std_mean_r_squared_species_significant.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'slope_ols'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_min_r_squared_species_merged = plot_slopes(df_mean_min_r_squared_species, field_name, predictor_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_min_r_squared_species_merged = plot_slopes(df_mean_min_r_squared_species_significant, field_name, \n",
    "                                                   predictor_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_mean_r_squared_species_merged = plot_slopes(df_mean_mean_r_squared_species, field_name, predictor_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_mean_r_squared_species_merged = plot_slopes(df_mean_mean_r_squared_species_significant, field_name, \n",
    "                                                    predictor_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_std_mean_r_squared_species_merged = plot_slopes(df_mean_std_mean_r_squared_species, field_name, \n",
    "                                                        predictor_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_std_mean_r_squared_species_merged = plot_slopes(df_mean_std_mean_r_squared_species_significant, \n",
    "                                                        field_name, predictor_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_mean_std_mean_r_squared_species_merged[\n",
    "    df_mean_std_mean_r_squared_species_merged['species_code'] == 'barswa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_mean_std_mean_r_squared_species_merged[\n",
    "    df_mean_std_mean_r_squared_species_merged['species_code'] == 'treswa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_mean_std_mean_r_squared_species_merged[\n",
    "    df_mean_std_mean_r_squared_species_merged['species_code'] == 'chiswi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_mean_std_mean_r_squared_species_merged[\n",
    "    df_mean_std_mean_r_squared_species_merged['species_code'] == 'purmar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mean_std_mean_r_squared_species_merged[\n",
    "    df_mean_std_mean_r_squared_species_merged['species_code'] == 'barswa'].sort_values(by='slope_ols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mean_std_mean_r_squared_species_merged[\n",
    "    df_mean_std_mean_r_squared_species_merged['species_code'] == 'treswa'].sort_values(by='slope_ols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mean_std_mean_r_squared_species_merged[\n",
    "    df_mean_std_mean_r_squared_species_merged['species_code'] == 'chiswi'].sort_values(by='slope_ols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_std_mean_r_squared_species_merged[\n",
    "    df_mean_std_mean_r_squared_species_merged['species_code'] == 'purmar'].sort_values(by='slope_ols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comp_species = df_first_of_species[['grid_cell', 'slope_first_of_season', 'species_code']].merge(\n",
    "#     df_mean_min_r_squared_species[['grid_cell', 'slope_mean', 'species_code']], \n",
    "#     on=['grid_cell', 'species_code'])\n",
    "\n",
    "# print('len(df_comp_species):', len(df_comp_species))\n",
    "\n",
    "# if len(df_comp_species) > 0:\n",
    "#     df_comp_species.plot('slope_mean', 'slope_first_of_season', kind='scatter')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_year = '2002'\n",
    "\n",
    "species = 'treswa'\n",
    "# species = 'barswa'\n",
    "# species = 'chiswi'\n",
    "\n",
    "sampled = 1\n",
    "\n",
    "random_state = 1\n",
    "\n",
    "df_first_of_sampled_random_states = pd.DataFrame()\n",
    "df_r_first_of_sampled_random_states = pd.DataFrame()\n",
    "\n",
    "for species in ['treswa', 'barswa', 'chiswi']:\n",
    "\n",
    "    sampled = 1\n",
    "\n",
    "    for random_state in range(1, 6):\n",
    "        \n",
    "        ###\n",
    "\n",
    "        df_first_of_sampled, df_grid_cells_sampled, df_r_first_of_sampled = main_function(\n",
    "            species, start_date, end_date, start_year, end_year, month, year, sampled, countries_states, \n",
    "            random_state)\n",
    "\n",
    "        df_first_of_sampled['species_code'] = species\n",
    "\n",
    "        df_first_of_sampled['random_state'] = random_state\n",
    "        df_r_first_of_sampled['random_state'] = random_state\n",
    "\n",
    "        df_first_of_sampled_random_states = df_first_of_sampled_random_states.append(df_first_of_sampled)\n",
    "        df_r_first_of_sampled_random_states = df_r_first_of_sampled_random_states.append(\n",
    "            df_r_first_of_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_first_of_not_sampled_species = pd.DataFrame()\n",
    "df_r_first_of_not_sampled_species = pd.DataFrame()\n",
    "\n",
    "for species in ['treswa', 'barswa', 'chiswi']:\n",
    "\n",
    "    sampled = 0\n",
    "    \n",
    "    ###\n",
    "\n",
    "    df_first_of_not_sampled, df_grid_cells_not_sampled, df_r_first_of_not_sampled = main_function(\n",
    "        species, start_date, end_date, start_year, end_year, month, year, sampled, countries_states)\n",
    "    \n",
    "    df_first_of_not_sampled['species_code'] = species\n",
    "    \n",
    "    df_first_of_not_sampled_species = df_first_of_not_sampled_species.append(df_first_of_not_sampled)\n",
    "    df_r_first_of_not_sampled_species = df_r_first_of_not_sampled_species.append(\n",
    "        df_r_first_of_not_sampled)\n",
    "    \n",
    "    ###\n",
    "\n",
    "    # df_mean, df_first_of, df_grid_cells, df_r_first_of, list_df_r_mean, list_df_r_comp = main_function(\n",
    "    #     species, start_date, end_date, month, year, countries_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_first_of_sampled_random_states.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_first_of_sampled = df_first_of_sampled_random_states[\n",
    "    ['species_code', 'grid_cell', 'year', 'first_of_season_arrival_day']].groupby(\n",
    "    ['species_code', 'grid_cell', 'year']).mean()\n",
    "df_mean_first_of_sampled = df_mean_first_of_sampled.rename(\n",
    "    columns={'first_of_season_arrival_day': 'mean_first_of_season_arrival_day'})\n",
    "\n",
    "df_var_first_of_sampled = df_first_of_sampled_random_states[\n",
    "    ['species_code', 'grid_cell', 'year', 'first_of_season_arrival_day']].groupby(\n",
    "    ['species_code', 'grid_cell', 'year']).var()\n",
    "df_var_first_of_sampled = df_var_first_of_sampled.rename(\n",
    "    columns={'first_of_season_arrival_day': 'variance_first_of_season_arrival_day'})\n",
    "\n",
    "df_std_first_of_sampled = df_first_of_sampled_random_states[\n",
    "    ['species_code', 'grid_cell', 'year', 'first_of_season_arrival_day']].groupby(\n",
    "    ['species_code', 'grid_cell', 'year']).std()\n",
    "df_std_first_of_sampled = df_std_first_of_sampled.rename(\n",
    "    columns={'first_of_season_arrival_day': 'standard_deviation_first_of_season_arrival_day'})\n",
    "\n",
    "df_stats_first_of_sampled = df_mean_first_of_sampled.merge(\n",
    "    df_var_first_of_sampled, left_index=True, right_index=True).merge(\n",
    "    df_std_first_of_sampled, left_index=True, right_index=True)\n",
    "df_stats_first_of_sampled = df_stats_first_of_sampled.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_mean_first_of_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_var_first_of_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_std_first_of_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stats_first_of_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_first_of_not_sampled_species.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_r_first_of_sampled_random_states.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_slopes_first_of_sampled = df_r_first_of_sampled_random_states[\n",
    "    ['species_code', 'grid_cell', 'slope_first_of_season_ols']].groupby(['species_code', 'grid_cell']).mean()\n",
    "df_mean_slopes_first_of_sampled = df_mean_slopes_first_of_sampled.rename(\n",
    "    columns={'slope_first_of_season_ols': 'mean_slope_first_of_season'})\n",
    "\n",
    "df_var_slopes_first_of_sampled = df_r_first_of_sampled_random_states[\n",
    "    ['species_code', 'grid_cell', 'slope_first_of_season_ols']].groupby(['species_code', 'grid_cell']).var()\n",
    "df_var_slopes_first_of_sampled = df_var_slopes_first_of_sampled.rename(\n",
    "    columns={'slope_first_of_season_ols': 'variance_slope_first_of_season'})\n",
    "\n",
    "df_std_slopes_first_of_sampled = df_r_first_of_sampled_random_states[\n",
    "    ['species_code', 'grid_cell', 'slope_first_of_season_ols']].groupby(['species_code', 'grid_cell']).std()\n",
    "df_std_slopes_first_of_sampled = df_std_slopes_first_of_sampled.rename(\n",
    "    columns={'slope_first_of_season_ols': 'standard_deviation_slope_first_of_season'})\n",
    "\n",
    "df_stats_slopes_first_of_sampled = df_mean_slopes_first_of_sampled.merge(\n",
    "    df_var_slopes_first_of_sampled, left_index=True, right_index=True).merge(\n",
    "    df_std_slopes_first_of_sampled, left_index=True, right_index=True)\n",
    "df_stats_slopes_first_of_sampled = df_stats_slopes_first_of_sampled.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mean_slopes_first_of_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_var_slopes_first_of_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_std_slopes_first_of_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_slopes_first_of_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_first_of_not_sampled_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = 'Elske/'\n",
    "filename = 'pheno_all.csv'\n",
    "\n",
    "df_insects = pd.read_csv(subdir + filename)\n",
    "\n",
    "print(len(df_insects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insects = df_insects.rename(columns={'body_size_mg': 'body_mass_mg'})\n",
    "df_insects['log_body_mass_mg'] = np.log(df_insects['body_mass_mg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insects.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_of_species_merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insects_fewer_cols = df_insects[['state', 'scientific_name', 'common_name', 'body_mass_mg', 'log_body_mass_mg', \n",
    "                                    'slope_year']]\n",
    "df_insects_fewer_cols = df_insects_fewer_cols.rename(columns={'state': 'location'})\n",
    "df_insects_fewer_cols = df_insects_fewer_cols.rename(columns={'slope_year': 'slope_arrival_day_year'})\n",
    "df_insects_fewer_cols['log_body_mass_mg'] = np.log(df_insects_fewer_cols['body_mass_mg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_of_species_fewer_cols = df_first_of_species_merged[[\n",
    "    'grid_cell', 'scientific_name', 'common_name', 'body_mass_mg', 'log_body_mass_mg', 'slope_first_of_season']]\n",
    "df_first_of_species_fewer_cols = df_first_of_species_fewer_cols.rename(columns={'grid_cell': 'location'})\n",
    "df_first_of_species_fewer_cols = df_first_of_species_fewer_cols.rename(\n",
    "    columns={'slope_first_of_season': 'slope_arrival_day_year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insects_fewer_cols.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_of_species_fewer_cols.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_of_migratory_o_a_i_insects = df_first_of_species_fewer_cols.append(df_insects_fewer_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_first_of_migratory_o_a_i_insects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(df_first_of_migratory_o_a_i_insects == len(df_first_of_species_fewer_cols) + len(df_insects_fewer_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_of_migratory_o_a_i_insects = df_first_of_migratory_o_a_i_insects.sort_values(by='body_mass_mg', \n",
    "                                                                                      ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_of_migratory_o_a_i_insects.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slopes_across_taxa(df):\n",
    "    \n",
    "    print(len(df['common_name'].unique()))\n",
    "    \n",
    "    color_values = matplotlib.cm.rainbow(np.linspace(0, 1, len(df['common_name'].unique())))\n",
    "    colors = dict(zip(df['common_name'].unique(), color_values))\n",
    "    \n",
    "    body_mass_field_name = 'log_body_mass_mg'\n",
    "#     body_mass_field_name = 'body_mass_mg'\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for species in list(df['common_name'].unique()):\n",
    "        df_subset = df[df['common_name'] == species]\n",
    "        df_subset.plot(ax=ax, kind='scatter', x=body_mass_field_name, y='slope_arrival_day_year', label=species, \n",
    "                       color=colors[species], figsize=(15,10))\n",
    "    \n",
    "#     plt.legend(loc='best')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.axhline(y=0, color='r', linestyle='-')\n",
    "    plt.xlabel('Natural logarithm of body mass (mg)')\n",
    "    plt.ylabel('Slope of arrival day as a function of year')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slopes_across_taxa(df_first_of_migratory_o_a_i_insects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slope?\n",
    "Residuals?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
